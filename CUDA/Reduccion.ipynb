{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reduccion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8yUaewFKWeC01s1Ryhluo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ludvins/Practicas_PDGE/blob/master/CUDA/Reduccion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qKIkA60S2B5"
      },
      "source": [
        "El objetivo de este ejercicio es familiarizarse con un tipo de operaciones\n",
        "muy común en computación científica: las reducciones. Una reducción\n",
        "es una combinación de todos los elementos de un vector en un valor\n",
        "único, utilizando para ello algún tipo de operador asociativo. Las\n",
        "implementaciones paralelas aprovechan esta asociatividad para calcular\n",
        "operaciones en paralelo, calculando el resultado en $O(\\log N)$ pasos sin\n",
        "incrementar el número de operaciones realizadas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEK3fZHHTIEp"
      },
      "source": [
        "En este ejercicio se trata de comparar diferentes patrones de acceso a\n",
        "los datos para ir asociando por pares los operandos de cada operación.\n",
        "Esto afecta al rendimiento de la memoria, y también a la complejidad de\n",
        "programación, ya que las expresiones que hay que crear para que los\n",
        "hilos generen los índices de acceso a sus datos en cada paso difieren en\n",
        "dificultad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrbpLUXsRdgB"
      },
      "source": [
        "# Diferentes paradigmas de reducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiYS46PhWlJ9"
      },
      "source": [
        "## Caso 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZdPb44FSWNQ"
      },
      "source": [
        "Este esquema de reducciónfunciona segun el siguiente esquema: (poner foto)\n",
        "\n",
        "- Se lanzan tantos threads como elementos hay en el vector.\n",
        "- Cada thread carga un elemento en un array de memoria compartida.\n",
        "- Aumentando el valor de traslación en el vector (stride) se hacen los siguientes pasos:\n",
        "  - Si el identificador del thread es mejor que 2*stride, añade a su posición la de la poscicion trasladada.\n",
        "\n",
        "  Esto resulta en hacer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ9cdR4HS7Ro",
        "outputId": "4216e9a4-e4ca-4902-ae25-4f0457c030a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile Reduction0.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define NUM_ELEMENTS 512\n",
        "\n",
        "// **===------------------------------------------------------------------===**\n",
        "//! @param g_idata  input data in global memory\n",
        "//                  result is expected in index 0 of g_idata\n",
        "//! @param n        input number of elements to scan from input data\n",
        "// **===------------------------------------------------------------------===**\n",
        "__global__ void reduction(float *g_data, int n){\n",
        "  int stride;\n",
        "  // Define shared memory\n",
        "  __shared__ float scratch[NUM_ELEMENTS];\n",
        "  // Load the shared memory\n",
        "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
        "  __syncthreads();\n",
        "  // Do sum reduction from shared memory\n",
        "  for (stride = 1 ; stride < blockDim.x; stride *= 2) {\n",
        "      __syncthreads();\n",
        "      if (threadIdx.x % (2*stride) == 0)\n",
        "              scratch[threadIdx.x] += scratch[threadIdx.x + stride];\n",
        "      \n",
        "  }\n",
        "  // Store results back to global memory\n",
        "  if(threadIdx.x == 0)\n",
        "    g_data[0] = scratch[0];\n",
        "  return;\n",
        "}\n",
        "\n",
        "float computeOnDevice(float* h_data, int num_elements)\n",
        "{\n",
        "  float* d_data = NULL;\n",
        "  float result;\n",
        "  // Memory allocation on device side\n",
        "  cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
        "  // Copy from host memory to device memory\n",
        "  cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int threads = num_elements;\n",
        "  // Invoke the kernel\n",
        "  reduction<<<1,threads>>>(d_data,num_elements);\n",
        "  // Copy from device memory back to host memory\n",
        "  cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  cudaFree(d_data);\n",
        "  return result;\n",
        "}\n",
        "\n",
        "\n",
        "  \n",
        "  void computeOnHost( float* reference, float* idata, const unsigned int len) \n",
        "{\n",
        "  reference[0] = 0;\n",
        "  double total_sum = 0;\n",
        "  unsigned int i;\n",
        "  for( i = 0; i < len; ++i) \n",
        "  {\n",
        "      total_sum += idata[i];\n",
        "  }\n",
        "  reference[0] = total_sum;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "// Program main\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "int main() {\n",
        "    int num_elements = NUM_ELEMENTS;\n",
        "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
        "    // allocate host memory to store the input data\n",
        "    float* h_data = (float*) malloc( array_mem_size);\n",
        "    // * No arguments: Randomly generate input data and compare against the host's \n",
        "    \n",
        "            // initialize the input data on the host to be integer values\n",
        "            // between 0 and 1000\n",
        "            for( unsigned int i = 0; i < num_elements; ++i) \n",
        "            {\n",
        "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
        "                h_data[i] = i*1.0;\n",
        "            }\n",
        "       \n",
        "        // compute reference solution\n",
        "    float reference = 0.0f;  \n",
        "    computeOnCPU(&reference , h_data, num_elements);\n",
        "  \n",
        "   \n",
        "    float result = computeOnDevice(h_data, num_elements);\n",
        "    // We can use an epsilon of 0 since values are integral and in a range \n",
        "    // that can be exactly represented\n",
        "    float epsilon = 0.0f;\n",
        "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
        "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
        "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
        "    // cleanup memory\n",
        "    free( h_data);\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing Reduction0.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6aIrzIsbQac",
        "outputId": "3049b7e2-238f-445c-b6fc-33d488b0e206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true Reduction0.cu -o red0 -lcudadevrt\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reduction0.cu(50): error: function \"computeOnDevice\" has already been defined\n",
            "\n",
            "Reduction0.cu(102): error: identifier \"computeOnCPU\" is undefined\n",
            "\n",
            "2 errors detected in the compilation of \"/tmp/tmpxft_00000178_00000000-8_Reduction0.cpp1.ii\".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhoWIYeJbVdZ",
        "outputId": "3b7dde7c-7bde-4521-e4ae-0db25805169b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./red0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test PASSED\n",
            "device: 130816.000000  host: 130816.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewu1PX44cvSo",
        "outputId": "35c5a250-933c-4b2a-cab4-568fc44e64c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./red0"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==710== NVPROF is profiling process 710, command: ./red\n",
            "Test PASSED\n",
            "device: 130816.000000  host: 130816.000000\n",
            "==710== Profiling application: ./red\n",
            "==710== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   67.92%  8.0630us         1  8.0630us  8.0630us  8.0630us  reduction(float*, int)\n",
            "                   16.44%  1.9520us         1  1.9520us  1.9520us  1.9520us  [CUDA memcpy HtoD]\n",
            "                   15.63%  1.8560us         1  1.8560us  1.8560us  1.8560us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.65%  197.40ms         1  197.40ms  197.40ms  197.40ms  cudaMalloc\n",
            "                    0.19%  371.29us         1  371.29us  371.29us  371.29us  cuDeviceTotalMem\n",
            "                    0.07%  144.66us        97  1.4910us     133ns  61.010us  cuDeviceGetAttribute\n",
            "                    0.04%  78.882us         1  78.882us  78.882us  78.882us  cudaFree\n",
            "                    0.02%  37.087us         2  18.543us  15.710us  21.377us  cudaMemcpy\n",
            "                    0.01%  27.858us         1  27.858us  27.858us  27.858us  cudaLaunchKernel\n",
            "                    0.01%  27.339us         1  27.339us  27.339us  27.339us  cuDeviceGetName\n",
            "                    0.00%  3.9600us         1  3.9600us  3.9600us  3.9600us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1630us         3     721ns     146ns  1.4840us  cuDeviceGetCount\n",
            "                    0.00%  1.3180us         2     659ns     284ns  1.0340us  cuDeviceGet\n",
            "                    0.00%     276ns         1     276ns     276ns     276ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN2Wk1d9hnpY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsmimchBWnXp"
      },
      "source": [
        "## Caso 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jErDJoLNWoD7",
        "outputId": "4ee4c1e0-9455-4eb8-fcb7-a37d9b46c592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile Reduction1.cu\n",
        "// includes, kernels\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "#define NUM_ELEMENTS 512\n",
        "// **===------------------------------------------------------------------===**\n",
        "//! @param g_idata  input data in global memory\n",
        "//                  result is expected in index 0 of g_idata\n",
        "//! @param n        input number of elements to scan from input data\n",
        "// **===------------------------------------------------------------------===**\n",
        "__global__ void reduction(float *g_data, int n)\n",
        "{\n",
        "  int stride;\n",
        "  // Define shared memory\n",
        "  __shared__ float scratch[NUM_ELEMENTS];\n",
        "  // Load the shared memory\n",
        "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
        "  if(threadIdx.x + blockDim.x < n)\n",
        "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
        "  __syncthreads();\n",
        "  // Do sum reduction from shared memory\n",
        " \n",
        "  for (stride = NUM_ELEMENTS / 2; stride >= 1; stride >>= 1)\n",
        "  {\n",
        "      if(threadIdx.x < stride)\n",
        "         scratch[threadIdx.x] += scratch[threadIdx.x + stride];\n",
        "      __syncthreads();\n",
        "  }\n",
        "  // Store results back to global memory\n",
        "  if(threadIdx.x == 0)\n",
        "    g_data[0] = scratch[0];\n",
        "  return;\n",
        "}\n",
        "\n",
        "  void computeOnHost( float* reference, float* idata, const unsigned int len) \n",
        "{\n",
        "  reference[0] = 0;\n",
        "  double total_sum = 0;\n",
        "  unsigned int i;\n",
        "  for( i = 0; i < len; ++i) \n",
        "  {\n",
        "      total_sum += idata[i];\n",
        "  }\n",
        "  reference[0] = total_sum;\n",
        "}\n",
        "\n",
        "float computeOnDevice(float* h_data, int num_elements)\n",
        "{\n",
        " float* d_data = NULL;\n",
        "  float result;\n",
        "  // Memory allocation on device side\n",
        "  cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
        "  // Copy from host memory to device memory\n",
        "  cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  int threads = (num_elements/2) + num_elements%2;\n",
        "  // Invoke the kernel\n",
        "  reduction<<<1,threads>>>(d_data,num_elements);\n",
        "  // Copy from device memory back to host memory\n",
        "  cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  cudaFree(d_data);\n",
        "  return result;\n",
        "}\n",
        "   \n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "// Program main\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "int main() {\n",
        "    int num_elements = NUM_ELEMENTS;\n",
        "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
        "    // allocate host memory to store the input data\n",
        "    float* h_data = (float*) malloc( array_mem_size);\n",
        "    // * No arguments: Randomly generate input data and compare against the host's \n",
        "    \n",
        "            // initialize the input data on the host to be integer values\n",
        "            // between 0 and 1000\n",
        "            for( unsigned int i = 0; i < num_elements; ++i) \n",
        "            {\n",
        "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
        "                h_data[i] = i*1.0;\n",
        "            }\n",
        "       \n",
        "        // compute reference solution\n",
        "    float reference = 0.0f;  \n",
        "    computeOnHost(&reference , h_data, num_elements);\n",
        "  \n",
        "   \n",
        "    float result = computeOnDevice(h_data, num_elements);\n",
        "    // We can use an epsilon of 0 since values are integral and in a range \n",
        "    // that can be exactly represented\n",
        "    float epsilon = 0.0f;\n",
        "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
        "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
        "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
        "    // cleanup memory\n",
        "    free( h_data);\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting Reduction1.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIn8z65HW6ie",
        "outputId": "e8529c05-7c9a-4e6f-834e-15fe467c6dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true Reduction1.cu -o red1 -lcudadevrt\n",
        "!./red1\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test PASSED\n",
            "device: 130816.000000  host: 130816.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StUiqMbhW9Kp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}