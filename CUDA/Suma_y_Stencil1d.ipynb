{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Suma_y_Stencil1d.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X7BxTkfPwSU2",
        "6rVyeFJ1YQWw",
        "8hBoDHP-twyR",
        "7LvhkbKTtz2F",
        "RDVz5Mh4vPUh",
        "iYHBfGFYveW6",
        "n5GADOwRvXYX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ludvins/Practicas_PDGE/blob/master/CUDA/Suma_y_Stencil1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOMJ-7QKs0ZZ"
      },
      "source": [
        "*Luis Antonio Ortega Andrés     \n",
        "Antonio Coín Castro*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99r-TI0k_V7-"
      },
      "source": [
        "# Introducción: información del sistema\n",
        "Comprobamos las características del sistema que nos ha proporcionado Google Colab. Utilizando `lscpu` podemos obtener diversas características de la CPU que utiliza el sistema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRmCimjj_eFD",
        "outputId": "d9c65914-6754-4a1a-dd80-8eedd4c4ffcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!lscpu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2200.000\n",
            "BogoMIPS:            4400.00\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeqzzH3ajW0c"
      },
      "source": [
        "El comando `free` nos permite conocer información sobre la memoria física y swap del sistema. Utilizamos el flag `-h` para indicar que buscamos tener la salida en un formato más legible (Megabytes, Gygabytes...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr4-mdOu_fo9",
        "outputId": "288ea689-e3f9-483e-a94e-36284b7b121d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!free -h"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        534M         10G        956K        1.9G         11G\n",
            "Swap:            0B          0B          0B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF0YFAOb_hiB"
      },
      "source": [
        "Verificamos la versión de Cuda instalada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w30QGcoZ_kv1",
        "outputId": "33ef848f-5c2a-40df-9894-3aa8e53fa1aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stCxtcXekQmf"
      },
      "source": [
        "Utilizamos la interfaz de configuración de sistemas de NVIDIA (NVIDIA System Management Interface) para conocer el estado de la tarjeta gráfica que vamos a utilizar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7oDGUCF_mBK",
        "outputId": "001b2905-6f64-49ea-a8eb-6079d5215109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Nov  6 20:15:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBfteA6XsqZD"
      },
      "source": [
        "Vemos cuál es el directorio de trabajo y su contenido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QbLCHaCsvb-",
        "outputId": "4d9f0ab2-63ea-4f2e-ef4b-2be1f3a95b57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd\n",
        "!ls -la\n",
        "!ls /"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Nov  6 20:14 .\n",
            "drwxr-xr-x 1 root root 4096 Nov  6 20:05 ..\n",
            "drwxr-xr-x 1 root root 4096 Nov  3 17:17 .config\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:30 sample_data\n",
            "-rw-r--r-- 1 root root 1054 Nov  6 20:14 suma1.cu\n",
            "bin\t datalab  home\t lib64\topt   run   swift\t       tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t       tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-1.15.2  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygCGApW0kmMa"
      },
      "source": [
        "Podemos ejecutar el código de ejemplo presente en la librería de Cuda que nos enumera las propiedades del dispositivo Cuda que existe en el sistema. Para ello, cambiamos de directorio a aquel donde se encuentra el código fuente:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egav_e4ULqaQ",
        "outputId": "0a5721eb-fe8a-4dc3-ab0c-aaa9697156e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/samples/1_Utilities/deviceQuery\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_heYpiyk_ow"
      },
      "source": [
        "El programa no se encuentra compilado, pero provee de un makefile para su fácil compilación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6sfqdvQLtAX",
        "outputId": "3efabe33-3f0b-4e68-ca32-39b810224925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!make"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery.o -c deviceQuery.cpp\n",
            "/usr/local/cuda-10.1/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery deviceQuery.o \n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../bin/x86_64/linux/release\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuXDl-JflIfY"
      },
      "source": [
        "Si ejecutamos el programa, obtenemos información interesante, como que el número máximo de threads por bloque que podemos utilizar es 1024:\n",
        "```\n",
        "Maximum number of threads per block: 1024\n",
        "```\n",
        "También vemos la dimensión máxima que podemos dar a cada dimensión de bloque y grid:\n",
        "```\n",
        "Max dimension size of a thread block (x,y,z): (1024, 1024, 64),\n",
        "Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKGfxLn7Lwje",
        "outputId": "742580fd-a386-4a19-d1eb-efa6e88f0a57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./deviceQuery"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          10.1 / 10.1\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15080 MBytes (15812263936 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 1\n",
            "Result = PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDLZ98eZugMy"
      },
      "source": [
        "Finalmente, creamos un directorio de trabajo y entramos en él."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR5GMtllujlE",
        "outputId": "35862657-9b76-48ad-a8aa-8e939d739eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir -p /content/workcuda\n",
        "%cd /content/workcuda"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/workcuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2CtfWTcAASW"
      },
      "source": [
        "# Ejercicio 1: suma de vectores\n",
        "\n",
        "Disponemos de un código que realiza la suma de los elementos de un vector, sobreescribiendo el resultado en uno de ellos. Discutiremos varias versiones con distintos enfoques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7BxTkfPwSU2"
      },
      "source": [
        "## Suma en CPU\n",
        "En primer lugar escribimos un código para hacer la suma en CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxHWXipwjBx",
        "outputId": "2b2704a9-8bd7-4b11-fdf1-8eb568ffa058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma0.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "void add(int n, float *x, float *y) {\n",
        "  for (int i=0; i < n; i++ ){\n",
        "    y[i]=x[i]+y[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  int N = 1 <<20; // N = 2^20 = 1024*1024= 1.048.576\n",
        "  float *x = new float[N];\n",
        "  float *y = new float[N];\n",
        "\n",
        "  // Medir tiempos\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "  \n",
        "  // Rellenar vectores\n",
        "  for (int i =0; i < N; i++ ){\n",
        "    x[i]= 1.0f;\n",
        "    y[i]= 2.0f;\n",
        "  }\n",
        "  \n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  // Sumar elementos\n",
        "  add(N, x, y);\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  \n",
        "  // Calcular errores\n",
        "  float maxError = 0.0f;\n",
        "  int contError = 0;\n",
        "  for (int i=0; i <N; i++){\n",
        "    maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
        "    if (y[i] != 3.0) contError++;\n",
        "  }\n",
        "\n",
        "  float milliseconds = 0;\n",
        "  cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "  std::cout << \"Elapsed Time (msecs): \" <<milliseconds << std::endl;\n",
        "\n",
        "  // Mostrar resultados\n",
        "  std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
        "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "  \n",
        "  // Limpieza\n",
        "  delete [] x;\n",
        "  delete [] y;\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing suma0.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad6cpwN1USKW"
      },
      "source": [
        "Compilamos y ejecutamos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdmc_m4YUQ6a",
        "outputId": "104df6cb-c086-4544-9110-45e33a0bbbb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma0.cu -o suma0 -lcudadevrt\n",
        "!./suma0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed Time (msecs): 3.58131\n",
            "Suma de 1048576 elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM9BmTgEU5pY"
      },
      "source": [
        "Vemos que, como esperábamos, se suman todos los elementos sin errores, y el tiempo de ejecución es de unos 3-4 ms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rVyeFJ1YQWw"
      },
      "source": [
        "## Suma en GPU con data race\n",
        "\n",
        "Vamos a programar una versión preliminar que se ejecuta en GPU, simplemente convirtiendo la versión CPU de forma \"ingenua\". Definimos como constantes globales el número de threads y el número de bloques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLcHtYIfYPqI",
        "outputId": "86eaf8ec-968c-4d5f-fd1c-340167475667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma1.cu\n",
        "\n",
        "#define THREADS 1\n",
        "#define BLOCKS 1\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "  for (int i =0; i < n; i++ ){\n",
        "    y[i]=x[i]+y[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  int N = 1 <<20;\n",
        "  float *x; \n",
        "  float *y;\n",
        "\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        "  \n",
        "  for (int i =0; i < N; i++ ){\n",
        "    x[i]= 1.0f;\n",
        "    y[i]= 2.0f;\n",
        "  }\n",
        "\n",
        "  add<<<BLOCKS,THREADS>>>(N, x, y);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  float maxError = 0.0f;\n",
        "  int contError = 0;\n",
        "  for (int i=0; i <N; i++){\n",
        "    maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
        "    if (y[i] != 3.0) contError++;\n",
        "  }\n",
        "\n",
        "  std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
        "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "  cudaFree (x);\n",
        "  cudaFree (y);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma1.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWqcAgflaD1M"
      },
      "source": [
        "Compilamos y ejecutamos el programa tal cual, aprovechando y obteniendo la información del *profiler* para medir tiempos. Al dejar 1 bloque y 1 thread, estamos haciendo una ejecución en GPU pero en serie, sin aprovechar el paralelismo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJeIcq_qaJwx",
        "outputId": "d5153758-160d-401e-bb96-9f34f6c3fd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma1.cu -o suma1 -lcudadevrt\n",
        "!nvprof ./suma1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==421== NVPROF is profiling process 421, command: ./suma1\n",
            "Suma de 1048576 elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n",
            "==421== Profiling application: ./suma1\n",
            "==421== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  126.84ms         1  126.84ms  126.84ms  126.84ms  add(int, float*, float*)\n",
            "      API calls:   61.84%  207.56ms         2  103.78ms  35.829us  207.52ms  cudaMallocManaged\n",
            "                   37.80%  126.85ms         1  126.85ms  126.85ms  126.85ms  cudaDeviceSynchronize\n",
            "                    0.16%  538.64us         2  269.32us  260.63us  278.01us  cudaFree\n",
            "                    0.11%  381.05us         1  381.05us  381.05us  381.05us  cuDeviceTotalMem\n",
            "                    0.05%  183.59us        97  1.8920us     164ns  84.451us  cuDeviceGetAttribute\n",
            "                    0.02%  51.969us         1  51.969us  51.969us  51.969us  cudaLaunchKernel\n",
            "                    0.01%  29.667us         1  29.667us  29.667us  29.667us  cuDeviceGetName\n",
            "                    0.01%  17.313us         1  17.313us  17.313us  17.313us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0010us         3     667ns     191ns  1.3200us  cuDeviceGetCount\n",
            "                    0.00%  1.1830us         2     591ns     395ns     788ns  cuDeviceGet\n",
            "                    0.00%     288ns         1     288ns     288ns     288ns  cuDeviceGetUuid\n",
            "\n",
            "==421== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  816.7360us  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  363.2320us  Device To Host\n",
            "      12         -         -         -           -  3.156160ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7IFUgPIcSBw"
      },
      "source": [
        "Vemos que la suma acaba sin errores, pero tarda más de 180 ms, unas 60 veces más que en CPU. Para intentar reducir este tiempo de ejecución, introducimos primero un paralelismo de threads, empleando 256 threads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egasdS5scReF",
        "outputId": "9ab52a64-0c7e-4dc6-edc6-1dfb21c52d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sed -i '/#define THREADS/c\\#define THREADS 256' suma1.cu\n",
        "!sed -i '/#define BLOCKS/c\\#define BLOCKS 1' suma1.cu\n",
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma1.cu -o suma1 -lcudadevrt\n",
        "!nvprof ./suma1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==604== NVPROF is profiling process 604, command: ./suma1\n",
            "Suma de 1048576 elementos\n",
            "Número de Errores: 2445\n",
            "Max error: 2\n",
            "==604== Profiling application: ./suma1\n",
            "==604== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  293.21ms         1  293.21ms  293.21ms  293.21ms  add(int, float*, float*)\n",
            "      API calls:   57.93%  293.23ms         1  293.23ms  293.23ms  293.23ms  cudaDeviceSynchronize\n",
            "                   41.83%  211.74ms         2  105.87ms  35.393us  211.71ms  cudaMallocManaged\n",
            "                    0.11%  552.91us         2  276.45us  268.46us  284.45us  cudaFree\n",
            "                    0.08%  400.16us         1  400.16us  400.16us  400.16us  cuDeviceTotalMem\n",
            "                    0.03%  166.71us        97  1.7180us     151ns  75.741us  cuDeviceGetAttribute\n",
            "                    0.01%  43.704us         1  43.704us  43.704us  43.704us  cudaLaunchKernel\n",
            "                    0.01%  33.707us         1  33.707us  33.707us  33.707us  cuDeviceGetName\n",
            "                    0.00%  3.0610us         1  3.0610us  3.0610us  3.0610us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.7440us         3     581ns     180ns  1.0580us  cuDeviceGetCount\n",
            "                    0.00%  1.3890us         2     694ns     443ns     946ns  cuDeviceGet\n",
            "                    0.00%     262ns         1     262ns     262ns     262ns  cuDeviceGetUuid\n",
            "\n",
            "==604== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  812.3520us  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  353.6320us  Device To Host\n",
            "      12         -         -         -           -  3.626304ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44LbFGJmgNzw"
      },
      "source": [
        "Vemos que, contrario a nuestras pretensiones, la suma ha tardado más, y con muchos más errores. El hecho de que tarde más se debe a que en cada thread estamos haciendo $N$ sumas, lo que introduce un cierto *overhead*. En cuanto a los errores, se deben a que, como cada thread accede a la memoria global y modifica el contenido del vector `y`, se producirán errores siempre que una hebra lea un valor después de que otra haya sobreescrito esa posición. Esto es lo que se conoce como *condición de carrera* o *data race*, y el hecho de que haya más o menos errores será aleatorio en función de los tiempos de lectura y escritura de las hebras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX8M96qHlADT"
      },
      "source": [
        "Podemos intentar hacer también un paralelismo de bloques, fijando 256 bloques con un único thread."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaIEop_Vgc6-",
        "outputId": "61f3f54b-bbe9-473d-ee48-40199f86f55f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sed -i '/#define THREADS/c\\#define THREADS 1' suma1.cu\n",
        "!sed -i '/#define BLOCKS/c\\#define BLOCKS 256' suma1.cu\n",
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma1.cu -o suma1 -lcudadevrt\n",
        "!nvprof ./suma1"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==656== NVPROF is profiling process 656, command: ./suma1\n",
            "Suma de 1048576 elementos\n",
            "Número de Errores: 1048573\n",
            "Max error: 234\n",
            "==656== Profiling application: ./suma1\n",
            "==656== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  270.85ms         1  270.85ms  270.85ms  270.85ms  add(int, float*, float*)\n",
            "      API calls:   55.66%  270.87ms         1  270.87ms  270.87ms  270.87ms  cudaDeviceSynchronize\n",
            "                   44.10%  214.64ms         2  107.32ms  35.790us  214.60ms  cudaMallocManaged\n",
            "                    0.12%  580.06us         2  290.03us  278.96us  301.10us  cudaFree\n",
            "                    0.07%  360.46us         1  360.46us  360.46us  360.46us  cuDeviceTotalMem\n",
            "                    0.03%  150.23us        97  1.5480us     141ns  63.245us  cuDeviceGetAttribute\n",
            "                    0.01%  39.951us         1  39.951us  39.951us  39.951us  cudaLaunchKernel\n",
            "                    0.01%  35.075us         1  35.075us  35.075us  35.075us  cuDeviceGetName\n",
            "                    0.00%  3.3900us         1  3.3900us  3.3900us  3.3900us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8200us         3     606ns     179ns  1.0950us  cuDeviceGetCount\n",
            "                    0.00%  1.1850us         2     592ns     372ns     813ns  cuDeviceGet\n",
            "                    0.00%     260ns         1     260ns     260ns     260ns  cuDeviceGetUuid\n",
            "\n",
            "==656== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  826.4320us  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  353.6000us  Device To Host\n",
            "      19         -         -         -           -  4.263424ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak5b8LtDlDtE"
      },
      "source": [
        "En este caso el tiempo de ejecución es similar al caso de paralelismo de threads, incluso un poco mayor. Lo que sí podemos destacar es que se producen errores en casi todas las posiciones del vector, de forma consistente en varias ejecuciones. Esto puede deberse a que, en el caso de varios bloques, solo se ejecuta cada vez un *warp* dentro de cada bloque, y en nuestro caso estos *warps* constarían de un único thread, por lo que es más difícil evitar las condiciones de carrera. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48cKzJ7wOSJ9"
      },
      "source": [
        "## Suma en GPU sin data race y combinando bloques y threads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stH50xXTOWRv"
      },
      "source": [
        "Vamos a modificar el código para evitar las condiciones de carrera y producir un resultado correcto en todos los casos. Para ello, necesitamos que cada hebra (o bloque) procese únicamente unas ciertas posiciones del vector, de forma que no haya conflictos y que se procese el vector completo. Para ello usamos las variables `threadIdx.x`, `blockIdx.x`, `blockDim.x` y `gridDim.x`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7eBitm8Ozer",
        "outputId": "64259321-6744-489c-e2cb-97ae7c3007b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma2.cu\n",
        "\n",
        "#define N (1<<20)\n",
        "#define THREADS 256\n",
        "#define BLOCKS 1\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "__global__ void add_all(int n, float *x, float *y) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < n)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "__global__ void add_threads(int n, float *x, float *y) {\n",
        "  for (int i = threadIdx.x; i < n; i += blockDim.x)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "__global__ void add_blocks(int n, float *x, float *y) {\n",
        "  for (int i = blockIdx.x; i < n; i += gridDim.x)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  float *x; \n",
        "  float *y;\n",
        "\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        "  \n",
        "  for (int i =0; i < N; i++ ){\n",
        "    x[i]= 1.0f;\n",
        "    y[i]= 2.0f;\n",
        "  }\n",
        "\n",
        "#if BLOCKS > 0 && THREADS == 1\n",
        "  add_blocks<<<BLOCKS,THREADS>>>(N, x, y);\n",
        "#elif BLOCKS == 1 && THREADS > 0\n",
        "  add_threads<<<BLOCKS,THREADS>>>(N, x, y);\n",
        "#else\n",
        "  add_all<<<BLOCKS,THREADS>>>(N, x, y);\n",
        "#endif\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  float maxError = 0.0f;\n",
        "  int contError = 0;\n",
        "  for (int i=0; i <N; i++){\n",
        "    maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
        "    if (y[i] != 3.0) contError++;\n",
        "  }\n",
        "\n",
        "  std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
        "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "  cudaFree (x);\n",
        "  cudaFree (y);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma2.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knkc7zyk-uJU"
      },
      "source": [
        "Probamos ahora a lanzar el kernel tanto con 1 bloque y 256 threads como con 256 threads y una sola hebra por bloque."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HSzy02K-1P2",
        "outputId": "29b3e283-e204-4cd9-a15c-146ec5e40360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sed -i '/#define THREADS/c\\#define THREADS 256' suma2.cu\n",
        "!sed -i '/#define BLOCKS/c\\#define BLOCKS 1' suma2.cu\n",
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
        "!nvprof ./suma2"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==998== NVPROF is profiling process 998, command: ./suma2\n",
            "Suma de 1048576 elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n",
            "==998== Profiling application: ./suma2\n",
            "==998== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  4.4753ms         1  4.4753ms  4.4753ms  4.4753ms  add_threads(int, float*, float*)\n",
            "      API calls:   97.25%  198.21ms         2  99.106ms  35.125us  198.18ms  cudaMallocManaged\n",
            "                    2.20%  4.4859ms         1  4.4859ms  4.4859ms  4.4859ms  cudaDeviceSynchronize\n",
            "                    0.27%  550.59us         2  275.29us  249.98us  300.61us  cudaFree\n",
            "                    0.17%  344.45us         1  344.45us  344.45us  344.45us  cuDeviceTotalMem\n",
            "                    0.07%  149.57us        97  1.5410us     132ns  57.314us  cuDeviceGetAttribute\n",
            "                    0.02%  45.544us         1  45.544us  45.544us  45.544us  cudaLaunchKernel\n",
            "                    0.01%  27.627us         1  27.627us  27.627us  27.627us  cuDeviceGetName\n",
            "                    0.00%  3.0630us         1  3.0630us  3.0630us  3.0630us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.7450us         3     581ns     128ns  1.2150us  cuDeviceGetCount\n",
            "                    0.00%  1.2490us         2     624ns     306ns     943ns  cuDeviceGet\n",
            "                    0.00%     279ns         1     279ns     279ns     279ns  cuDeviceGetUuid\n",
            "\n",
            "==998== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  808.6720us  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  362.1120us  Device To Host\n",
            "      12         -         -         -           -  2.762496ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJbWjlIWBmos",
        "outputId": "d2f7dd33-9ac5-4d54-ebf6-45798c135f16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sed -i '/#define THREADS/c\\#define THREADS 1' suma2.cu\n",
        "!sed -i '/#define BLOCKS/c\\#define BLOCKS 256' suma2.cu\n",
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
        "!nvprof ./suma2"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1048== NVPROF is profiling process 1048, command: ./suma2\n",
            "Suma de 1048576 elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n",
            "==1048== Profiling application: ./suma2\n",
            "==1048== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  4.1395ms         1  4.1395ms  4.1395ms  4.1395ms  add_blocks(int, float*, float*)\n",
            "      API calls:   97.43%  198.91ms         2  99.456ms  31.638us  198.88ms  cudaMallocManaged\n",
            "                    2.03%  4.1477ms         1  4.1477ms  4.1477ms  4.1477ms  cudaDeviceSynchronize\n",
            "                    0.27%  542.89us         2  271.45us  268.33us  274.56us  cudaFree\n",
            "                    0.17%  346.14us         1  346.14us  346.14us  346.14us  cuDeviceTotalMem\n",
            "                    0.07%  142.00us        97  1.4630us     134ns  62.884us  cuDeviceGetAttribute\n",
            "                    0.02%  36.952us         1  36.952us  36.952us  36.952us  cudaLaunchKernel\n",
            "                    0.01%  28.646us         1  28.646us  28.646us  28.646us  cuDeviceGetName\n",
            "                    0.00%  3.0430us         1  3.0430us  3.0430us  3.0430us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.9560us         3     652ns     142ns  1.3210us  cuDeviceGetCount\n",
            "                    0.00%  1.1320us         2     566ns     271ns     861ns  cuDeviceGet\n",
            "                    0.00%     280ns         1     280ns     280ns     280ns  cuDeviceGetUuid\n",
            "\n",
            "==1048== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  807.0400us  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  363.8400us  Device To Host\n",
            "      12         -         -         -           -  2.551584ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XuiZgwmBuXh"
      },
      "source": [
        "Vemos que en ambos casos todas las sumas se realizan correctamente (hay 0 errores), y se reduce notablemente el tiempo de ejecución de la suma, llegando hasta los 4 ms. \n",
        "\n",
        "Podemos probar, por ejemplo, a aumentar el número de threads, y vemos cómo se reduce aún más el tiempo de ejecución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mss-cX6wCJg6",
        "outputId": "3fa05946-3cc2-47f2-a13a-976decf4720a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sed -i '/#define THREADS/c\\#define THREADS 1024' suma2.cu\n",
        "!sed -i '/#define BLOCKS/c\\#define BLOCKS 1' suma2.cu\n",
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
        "!nvprof ./suma2"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1100== NVPROF is profiling process 1100, command: ./suma2\n",
            "Suma de 1048576 elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n",
            "==1100== Profiling application: ./suma2\n",
            "==1100== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  3.5332ms         1  3.5332ms  3.5332ms  3.5332ms  add_threads(int, float*, float*)\n",
            "      API calls:   97.72%  200.43ms         2  100.22ms  36.977us  200.40ms  cudaMallocManaged\n",
            "                    1.73%  3.5433ms         1  3.5433ms  3.5433ms  3.5433ms  cudaDeviceSynchronize\n",
            "                    0.26%  527.04us         2  263.52us  257.99us  269.05us  cudaFree\n",
            "                    0.19%  385.01us         1  385.01us  385.01us  385.01us  cuDeviceTotalMem\n",
            "                    0.07%  144.75us        97  1.4920us     132ns  60.551us  cuDeviceGetAttribute\n",
            "                    0.02%  39.303us         1  39.303us  39.303us  39.303us  cudaLaunchKernel\n",
            "                    0.02%  31.175us         1  31.175us  31.175us  31.175us  cuDeviceGetName\n",
            "                    0.00%  3.9100us         1  3.9100us  3.9100us  3.9100us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8160us         3     605ns     158ns  1.2220us  cuDeviceGetCount\n",
            "                    0.00%  1.5000us         2     750ns     305ns  1.1950us  cuDeviceGet\n",
            "                    0.00%     252ns         1     252ns     252ns     252ns  cuDeviceGetUuid\n",
            "\n",
            "==1100== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  822.1760us  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  363.7760us  Device To Host\n",
            "      15         -         -         -           -  3.029344ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmyV4CtLGm1v"
      },
      "source": [
        "Para la última versión, utilizamos tanto bloques como threads. La idea aquí es precalcular el número necesario de bloques dado un número de threads, para que todos los elementos se procesen de forma adecuada y sin errores. Si $TPB$ es el número de threads por bloque y $N$ es el tamaño del vector a sumar, el número de bloques óptimo, $NB$, viene dado por:\n",
        "\n",
        "$$NB=\\frac{N+TPB-1}{TPB}.$$\n",
        "\n",
        "Es decir, dividimos el número de elementos a procesar entre el número de threads por bloque, teniendo en cuenta que es posible que haya que redondear si $N$ no es una potencia de $TPB$. En el propio kernel añadimos una comprobación `if (i < n)` para asegurarnos que no accedemos a posiciones ilegales del vector.\n",
        "\n",
        "De esta forma, si $N$ es multiplo de $TPB$, se tiene que\n",
        "\n",
        "$$\n",
        "NB=\\frac{N + TPB - 1}{TPB} = \\frac{N}{TPB} + 1 - \\frac{1}{TPB} = K + 1 -\\frac{1}{TPB},\n",
        "$$\n",
        "\n",
        "lo cual tras transformarlo a entero resultaría en $NB=K = N/TPB \\in \\mathbb{N}$. En caso de no ser múltiplos, $N$ se descompone como $N_1 + N_2$, ambos enteros, donde $N_1$ sí es multiplo de $TPB$ y $1 \\leq N_2 < TPB$. En este caso:\n",
        "\n",
        "$$\n",
        "\\frac{N + TPB - 1}{TPB} = \\frac{N_1}{TPB} + \\frac{N_2}{TPB} + 1 - \\frac{1}{TPB} = K + 1 + \\frac{N_2}{TPB} -\\frac{1}{TPB}.\n",
        "$$\n",
        "\n",
        "Pero por por ser $1 \\leq N_2 < TPB$ y $N_2 \\in \\mathbb{N}$, tenemos: \n",
        "$$\n",
        "0 \\leq \\frac{N_2}{TPB} -\\frac{1}{TPB} < TPB.\n",
        "$$\n",
        "\n",
        "Así, al convertir a entero obtenemos en total $NB=K + 1 = \\dfrac{N_1}{TPB} + 1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmQ_wRKmE1B2",
        "outputId": "c8bb240f-3048-4711-fe25-e534fa912f93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sed -i '/#define THREADS/c\\#define THREADS 256' suma2.cu\n",
        "!sed -i '/#define BLOCKS/c\\#define BLOCKS ((N + THREADS - 1) / THREADS)' suma2.cu\n",
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
        "!nvprof ./suma2"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1272== NVPROF is profiling process 1272, command: ./suma2\n",
            "Suma de 1048576 elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n",
            "==1272== Profiling application: ./suma2\n",
            "==1272== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  2.8820ms         1  2.8820ms  2.8820ms  2.8820ms  add_all(int, float*, float*)\n",
            "      API calls:   98.05%  201.23ms         2  100.62ms  34.606us  201.20ms  cudaMallocManaged\n",
            "                    1.43%  2.9288ms         1  2.9288ms  2.9288ms  2.9288ms  cudaDeviceSynchronize\n",
            "                    0.25%  521.81us         2  260.91us  253.91us  267.90us  cudaFree\n",
            "                    0.16%  332.80us         1  332.80us  332.80us  332.80us  cuDeviceTotalMem\n",
            "                    0.07%  142.79us        97  1.4720us     129ns  58.247us  cuDeviceGetAttribute\n",
            "                    0.02%  35.906us         1  35.906us  35.906us  35.906us  cudaLaunchKernel\n",
            "                    0.01%  25.355us         1  25.355us  25.355us  25.355us  cuDeviceGetName\n",
            "                    0.00%  3.1210us         1  3.1210us  3.1210us  3.1210us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2250us         3     741ns     146ns  1.6150us  cuDeviceGetCount\n",
            "                    0.00%  1.2680us         2     634ns     258ns  1.0100us  cuDeviceGet\n",
            "                    0.00%     254ns         1     254ns     254ns     254ns  cuDeviceGetUuid\n",
            "\n",
            "==1272== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     136  60.234KB  4.0000KB  956.00KB  8.000000MB  1.022080ms  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  361.9200us  Device To Host\n",
            "      11         -         -         -           -  2.833856ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seHzLBHHFO2W"
      },
      "source": [
        "Vemos que seguimos sin obtener errores, y el tiempo de ejecución es aún más bajo, menos de 3 ms. Si aumentásemos el número de threads obtendríamos un tiempo de ejecución aún menor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXhdA6K4Tm6A"
      },
      "source": [
        "### Mejora en el kernel\n",
        "\n",
        "En el código anterior podríamos haber considerado la siguiente modificación del kernel para sumar los elementos del vector usando bloques y threads:\n",
        "\n",
        "```python\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "  for (int i = index; i < n; i += stride)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "```\n",
        "\n",
        "Como podemos ver en [el blog de Nvidia](https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/), utilizar esta estrategia tiene una serie de ventajas, siendo la principal de ellas que podemos manejar vectores de tamaños arbitrarios, y no estaríamos limitados por el máximo tamaño de grid en la dimensión `x` (que en nuestro caso vimos antes que es 2147483647)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COrmRBS0GBqw"
      },
      "source": [
        "### Otra operación matemática con más elementos\n",
        "\n",
        "Finalmente hacemos una prueba cambiando la complejidad de la operación matemática, por ejemplo a la división. También aumentamos el número de elementos del vector por ejemplo a $2^{30}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X89gM5I_GcUn",
        "outputId": "b737ce0d-2d85-4da7-d4f5-998eccdbfd34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile div.cu\n",
        "\n",
        "#define N (1<<30)\n",
        "#define THREADS 256\n",
        "#define BLOCKS ((N + THREADS - 1)/THREADS)\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "__global__ void div(int n, float *x, float *y) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < n)\n",
        "    y[i] = x[i] / y[i];\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  float *x; \n",
        "  float *y;\n",
        "\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        "  \n",
        "  for (int i =0; i < N; i++ ){\n",
        "    x[i]= 1.0f;\n",
        "    y[i]= 2.0f;\n",
        "  }\n",
        "\n",
        "  div<<<BLOCKS,THREADS>>>(N, x, y);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  float maxError = 0.0f;\n",
        "  int contError = 0;\n",
        "  for (int i=0; i <N; i++){\n",
        "    maxError=fmax(maxError,fabs(y[i]-0.5f));\n",
        "    if (y[i] != 0.5) contError++;\n",
        "  }\n",
        "\n",
        "  std::cout << \"División de \" << N << \" elementos\" << std::endl;\n",
        "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "  cudaFree (x);\n",
        "  cudaFree (y);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting div.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kJsziWwG3T-",
        "outputId": "ca46d9db-c047-496d-eaf7-9ff74741fec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true div.cu -o div -lcudadevrt\n",
        "!nvprof ./div"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1436== NVPROF is profiling process 1436, command: ./div\n",
            "División de 1073741824 elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n",
            "==1436== Profiling application: ./div\n",
            "==1436== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  2.73308s         1  2.73308s  2.73308s  2.73308s  div(int, float*, float*)\n",
            "      API calls:   80.38%  2.73310s         1  2.73310s  2.73310s  2.73310s  cudaDeviceSynchronize\n",
            "                   13.78%  468.72ms         2  234.36ms  205.23ms  263.48ms  cudaFree\n",
            "                    5.82%  197.77ms         2  98.883ms  47.955us  197.72ms  cudaMallocManaged\n",
            "                    0.01%  390.23us         1  390.23us  390.23us  390.23us  cuDeviceTotalMem\n",
            "                    0.00%  135.61us        97  1.3980us     135ns  56.342us  cuDeviceGetAttribute\n",
            "                    0.00%  80.302us         1  80.302us  80.302us  80.302us  cudaLaunchKernel\n",
            "                    0.00%  27.397us         1  27.397us  27.397us  27.397us  cuDeviceGetName\n",
            "                    0.00%  3.1740us         1  3.1740us  3.1740us  3.1740us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.4790us         3     493ns     152ns     977ns  cuDeviceGetCount\n",
            "                    0.00%  1.0940us         2     547ns     283ns     811ns  cuDeviceGet\n",
            "                    0.00%     258ns         1     258ns     258ns     258ns  cuDeviceGetUuid\n",
            "\n",
            "==1436== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "  132424  63.346KB  4.0000KB  0.9961MB  8.000000GB   1.002939s  Host To Device\n",
            "   24574  170.68KB  4.0000KB  0.9961MB  3.999939GB  368.3337ms  Device To Host\n",
            "   11506         -         -         -           -   2.742842s  Gpu page fault groups\n",
            "Total CPU Page faults: 36864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYLHwWRFHI6m"
      },
      "source": [
        "Seguimos sin tener errores, aunque ahora el tiempo de las divisiones es mayor, llegando a los 2 s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hBoDHP-twyR"
      },
      "source": [
        "# Ejercicio 2: suma de matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMnDmBzfvAYH",
        "outputId": "b62abcf5-38cf-4f71-be46-f68757010f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile suma_mat.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "// Definimos las dimensiones de las matrices\n",
        "#define R 512\n",
        "#define C 512\n",
        "\n",
        "// __global__ indica que se ejecuta en el dispositivo, por lo tanto\n",
        "// x, y,deben apuntar a memoria en el dispositivo.\n",
        "\n",
        "__global__ void add(float *x, float *y) {\n",
        "    \n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int index = i*R + j;\n",
        "    if (index < R*C)\n",
        "      y[index] = x[index] + y[index];\n",
        "}\n",
        "\n",
        "\n",
        "// Define number of threads per block\n",
        "#define THREADS_PER_BLOCK 32\n",
        "\n",
        "int main(void) {\n",
        "    // Inicializamos las variables\n",
        "    float *x, *y;                 // = new float[N];\n",
        "    float *d_x, *d_y;             // = new float[N]; \n",
        "    // Calculamos el tamaño de las matrices\n",
        "    int size = C*R*sizeof(float);\n",
        "\n",
        "    // Reservamos memoria en el dispositivo.\n",
        "    cudaMalloc((void **)&d_x, size);\n",
        "    cudaMalloc((void **)&d_y, size);\n",
        "\n",
        "    // Reservamos memoria en el host, trataremos las matrices como vectores\n",
        "    // con la dimension correspondiente y accederemos a ellos usando 2 indices.\n",
        "    x = (float *)malloc(R*C*sizeof(float*));\n",
        "    y = (float *)malloc(R*C*sizeof(float*));\n",
        "\n",
        "    // Inicializamos los datos\n",
        "    for (int i =0; i < R; i++ ){\n",
        "        for (int j = 0; j < C; j++){\n",
        "            x[i*R + j] = 1.0f;\n",
        "            y[i*R + j] = 2.0f;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copiamos los valores al dispositivo\n",
        "    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Creamos los objetos dim3 tanto para el Grid como para el bloque.\n",
        "    dim3 dimGrid ( (R + THREADS_PER_BLOCK - 1)/THREADS_PER_BLOCK , (C + THREADS_PER_BLOCK - 1)/THREADS_PER_BLOCK ,1 ) ;\n",
        "    // Definimos la dimension del bloque.\n",
        "    dim3 dimBlock( THREADS_PER_BLOCK, THREADS_PER_BLOCK, 1 ) ;\n",
        "\n",
        "    // Lamzamos la función en el dispositivo.\n",
        "    add<<<dimGrid, dimBlock>>>(d_x, d_y);\n",
        "\n",
        "    // Esperamos que se realicen todas las operaciones.\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copiamos el resultado al host.\n",
        "    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    // Comprobamos los resultados\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "   \n",
        "    for (int i=0; i <R; i++){\n",
        "        for (int j = 0; j < C; j++){\n",
        "          maxError=fmax(maxError,fabs(y[i*R + j]-3.0f));\n",
        "          if (y[i*R + j] != 3.0) contError++; \n",
        "        }\n",
        "    }\n",
        "    std::cout << \"Suma de \" << R*C << \" Elementos\" << std::endl;\n",
        "    std::cout << \"Número de Errores: \" << contError << std::endl;\n",
        "    std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "    // Liberamos la memoria tanto en el host como en el dispositivo.\n",
        "    free(x); free(y);\n",
        "    cudaFree(d_x); cudaFree(d_y);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma_mat.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtes1wA0vAYe"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma_mat.cu -o suma_mat -lcudadevrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os4f9Dd7vAYq",
        "outputId": "6dc211ea-2822-4f22-b5e7-51436019fed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!./suma_mat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "suma de 262144 Elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LvhkbKTtz2F"
      },
      "source": [
        "# Ejercicio 3: Stencil1d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDVz5Mh4vPUh"
      },
      "source": [
        "## Versión sin memoria compartida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlz3mwX1vPUo",
        "outputId": "e78a3843-db80-43b6-eee9-6f5a367c311a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile 1destencilexercise_v1.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        3\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "      cudaGetErrorString(error), \\\n",
        "      __FILE__, __LINE__); \\\n",
        "    exit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out) {\n",
        "    // Indice global de la posicion central de los datos del spencil que va a usar el thread.\n",
        "    int index = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\n",
        "    // Realizamos la operación del spencil\n",
        "    int result = 0;\n",
        "    for (int offset = -RADIUS; offset <= RADIUS; offset++)\n",
        "        result += in[index + offset];\n",
        "\n",
        "    // Guardamos el resultado\n",
        "    out[index-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Incializamos los datos en el host\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "    h_in[i] = 1; // Con un valor de 1 y un radio de 3, el array de resultados deberia ser de 7's.\n",
        "\n",
        "  // Reservamos memoria en el dispositivo\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copiamos los datos en la GPU\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  // Aplicamos el spencil\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  // Copiamos los resultados\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verificamos que se ha hecho correctamente\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "    if (h_out[i] != 7)\n",
        "    {\n",
        "      printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "      break;\n",
        "    }\n",
        "\n",
        "  if (i == NUM_ELEMENTS)\n",
        "    printf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Liberamos memoria\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 1destencilexercise_v1.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqC_IrbAvPU6",
        "outputId": "7541cc59-6ec7-459b-a4a2-a87ba6bc0b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true 1destencilexercise_v1.cu -o 1destencilexercise -lcudadevrt\n",
        "!./1destencilexercise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUCCESS!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oscb-QwIvPVJ"
      },
      "source": [
        "Comprobamos el comportamiento temporal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1dY0qmyvPVL",
        "outputId": "7670b839-fbe5-4498-9e3a-83cc8ba7ef4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!nvprof ./1destencilexercise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==575== NVPROF is profiling process 575, command: ./1destencilexercise\n",
            "SUCCESS!\n",
            "==575== Profiling application: ./1destencilexercise\n",
            "==575== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   37.81%  4.4160us         1  4.4160us  4.4160us  4.4160us  [CUDA memcpy DtoH]\n",
            "                   36.16%  4.2240us         1  4.2240us  4.2240us  4.2240us  [CUDA memcpy HtoD]\n",
            "                   26.03%  3.0400us         1  3.0400us  3.0400us  3.0400us  stencil_1d(int*, int*)\n",
            "      API calls:   99.61%  205.42ms         2  102.71ms  7.3560us  205.41ms  cudaMalloc\n",
            "                    0.18%  367.52us         1  367.52us  367.52us  367.52us  cuDeviceTotalMem\n",
            "                    0.07%  152.23us        97  1.5690us     145ns  64.354us  cuDeviceGetAttribute\n",
            "                    0.06%  127.92us         2  63.961us  14.654us  113.27us  cudaFree\n",
            "                    0.04%  84.581us         2  42.290us  33.218us  51.363us  cudaMemcpy\n",
            "                    0.02%  31.233us         1  31.233us  31.233us  31.233us  cuDeviceGetName\n",
            "                    0.01%  25.791us         1  25.791us  25.791us  25.791us  cudaLaunchKernel\n",
            "                    0.00%  3.5840us         1  3.5840us  3.5840us  3.5840us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8140us         3     604ns     171ns  1.1390us  cuDeviceGetCount\n",
            "                    0.00%  1.2090us         2     604ns     310ns     899ns  cuDeviceGet\n",
            "                    0.00%     290ns         1     290ns     290ns     290ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL7LaQpovPVS"
      },
      "source": [
        "Al no utilizar memoria compartida, la mayoria del tiempo se dedica a copia de elementos.\n",
        "\n",
        "**TODO**: 2. Use el generador de perfiles para determinar cuál es el problema.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsk9RkxVt1hn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYHBfGFYveW6"
      },
      "source": [
        "## Versión con memoria compartida sin sincronización de threads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgXVrCDdveW-",
        "outputId": "cb9cc700-8075-4e52-88be-334a505c9004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile 1destencilexercise_v2.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        3\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "      cudaGetErrorString(error), \\\n",
        "      __FILE__, __LINE__); \\\n",
        "    exit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out) \n",
        "{\n",
        "    // Reservamos la memoria compartida\n",
        "    __shared__ int temp[BLOCK_SIZE + 2*RADIUS];\n",
        "    // Indice central en el array global\n",
        "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "    // Indice centran en el array local\n",
        "    int lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "    // Leemos los puntos a la memoria compartida\n",
        "    temp[lindex] = in[gindex];\n",
        "    if (threadIdx.x < RADIUS) \n",
        "    {\n",
        "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "    }\n",
        "\n",
        "    // Hacemos la operación\n",
        "    int result = 0;\n",
        "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "        result += temp[lindex + offset];\n",
        "\n",
        "    // Guardamos el resultado\n",
        "    out[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  // Ejecutamos el código 100 veces independientes\n",
        "  for (int j = 0; j < 100; j++){\n",
        "      unsigned int i;\n",
        "      int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "      int *d_in, *d_out;\n",
        "\n",
        "      // Inicializamos los datos\n",
        "      for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "          h_in[i] = 1; \n",
        "\n",
        "      // Reserva memoria en la GPU\n",
        "      cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "      cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "      // Copiar los datos al dispositivo\n",
        "      cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "      stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "      cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "      for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "        if (h_out[i] != 7)\n",
        "        {\n",
        "          printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "          break;\n",
        "        }\n",
        "\n",
        "      // Free out memory\n",
        "      cudaFree(d_in);\n",
        "      cudaFree(d_out);\n",
        "      cudaDeviceReset();\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 1destencilexercise_v2.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6RkXHZSveXO"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true 1destencilexercise_v2.cu -o 1destencilexercise -lcudadevrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26v663reveXW",
        "outputId": "016dd6b8-569f-4902-f25e-b28a8fa184bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!./1destencilexercise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[63] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[95] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[95] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[63] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n",
            "Element h_out[62] == 6 != 7\n",
            "Element h_out[61] == 6 != 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5GADOwRvXYX"
      },
      "source": [
        "## Versión con memoria compartida y sincronización de threads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqVn3FvwvXYe",
        "outputId": "1df4ffcb-81f8-4c52-b390-0f9460880556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile 1destencilexercise_v3.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        3\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "      cudaGetErrorString(error), \\\n",
        "      __FILE__, __LINE__); \\\n",
        "    exit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out) \n",
        "{\n",
        "    __shared__ int temp[BLOCK_SIZE + 2*RADIUS];\n",
        "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "    int lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "    // Read input elements into shared memory\n",
        "    temp[lindex] = in[gindex];\n",
        "    if (threadIdx.x < RADIUS) \n",
        "    {\n",
        "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "    }\n",
        "    __syncthreads ();\n",
        "    // Apply the stencil\n",
        "    int result = 0;\n",
        "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "        result += temp[lindex + offset];\n",
        "\n",
        "    // Store the result\n",
        "    out[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "      unsigned int i;\n",
        "      int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "      int *d_in, *d_out;\n",
        "\n",
        "    // Initialize host data\n",
        "    for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "      h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "    // Allocate space on the device\n",
        "    cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "    cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "    // Copy input data to device\n",
        "    cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "    stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "    cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "    // Verify every out value is 7\n",
        "    for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "      if (h_out[i] != 7)\n",
        "      {\n",
        "        printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "        break;\n",
        "      }\n",
        " \n",
        "  if (i == NUM_ELEMENTS)\n",
        "    printf(\"SUCCESS!\\n\");\n",
        "\n",
        "\n",
        "    // Free out memory\n",
        "    cudaFree(d_in);\n",
        "    cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 1destencilexercise_v3.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AzCmOr9vXY1",
        "outputId": "00e6ba8c-f833-4e00-d8dc-6163f71b5e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true 1destencilexercise_v3.cu -o 1destencilexercise -lcudadevrt\n",
        "!./1destencilexercise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUCCESS!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KktJ2nLivXZB",
        "outputId": "12be9d22-bae6-4264-d437-64d3e9c65ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!nvprof ./1destencilexercise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==881== NVPROF is profiling process 881, command: ./1destencilexercise\n",
            "SUCCESS!\n",
            "==881== Profiling application: ./1destencilexercise\n",
            "==881== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   37.06%  4.3520us         1  4.3520us  4.3520us  4.3520us  [CUDA memcpy DtoH]\n",
            "                   35.97%  4.2240us         1  4.2240us  4.2240us  4.2240us  [CUDA memcpy HtoD]\n",
            "                   26.98%  3.1680us         1  3.1680us  3.1680us  3.1680us  stencil_1d(int*, int*)\n",
            "      API calls:   99.61%  192.38ms         2  96.188ms  6.8640us  192.37ms  cudaMalloc\n",
            "                    0.20%  382.92us         1  382.92us  382.92us  382.92us  cuDeviceTotalMem\n",
            "                    0.07%  144.48us        97  1.4890us     164ns  59.230us  cuDeviceGetAttribute\n",
            "                    0.05%  100.27us         2  50.132us  12.964us  87.301us  cudaFree\n",
            "                    0.04%  71.811us         2  35.905us  30.655us  41.156us  cudaMemcpy\n",
            "                    0.01%  28.067us         1  28.067us  28.067us  28.067us  cuDeviceGetName\n",
            "                    0.01%  26.077us         1  26.077us  26.077us  26.077us  cudaLaunchKernel\n",
            "                    0.00%  3.7350us         1  3.7350us  3.7350us  3.7350us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.7960us         3     598ns     170ns  1.1880us  cuDeviceGetCount\n",
            "                    0.00%  1.4130us         2     706ns     374ns  1.0390us  cuDeviceGet\n",
            "                    0.00%     290ns         1     290ns     290ns     290ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjWG7D2ZvXZK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}