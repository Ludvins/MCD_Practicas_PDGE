{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ludvins/Practicas_PDGE/blob/master/CUDA/Suma_y_Stencil1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOMJ-7QKs0ZZ"
   },
   "source": [
    "*Luis Antonio Ortega Andrés     \n",
    "Antonio Coín Castro*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99r-TI0k_V7-"
   },
   "source": [
    "# Introducción: información del sistema\n",
    "Comprobamos las características del sistema que nos ha proporcionado Google Colab. Utilizando `lscpu` podemos obtener diversas características de la CPU que utiliza el sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRmCimjj_eFD",
    "outputId": "d9c65914-6754-4a1a-dd80-8eedd4c4ffcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:        x86_64\n",
      "CPU op-mode(s):      32-bit, 64-bit\n",
      "Byte Order:          Little Endian\n",
      "CPU(s):              2\n",
      "On-line CPU(s) list: 0,1\n",
      "Thread(s) per core:  2\n",
      "Core(s) per socket:  1\n",
      "Socket(s):           1\n",
      "NUMA node(s):        1\n",
      "Vendor ID:           GenuineIntel\n",
      "CPU family:          6\n",
      "Model:               79\n",
      "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "Stepping:            0\n",
      "CPU MHz:             2200.000\n",
      "BogoMIPS:            4400.00\n",
      "Hypervisor vendor:   KVM\n",
      "Virtualization type: full\n",
      "L1d cache:           32K\n",
      "L1i cache:           32K\n",
      "L2 cache:            256K\n",
      "L3 cache:            56320K\n",
      "NUMA node0 CPU(s):   0,1\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeqzzH3ajW0c"
   },
   "source": [
    "El comando `free` nos permite conocer información sobre la memoria física y swap del sistema. Utilizamos el flag `-h` para indicar que buscamos tener la salida en un formato más legible (Megabytes, Gygabytes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mr4-mdOu_fo9",
    "outputId": "288ea689-e3f9-483e-a94e-36284b7b121d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            12G        534M         10G        956K        1.9G         11G\n",
      "Swap:            0B          0B          0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF0YFAOb_hiB"
   },
   "source": [
    "Verificamos la versión de Cuda instalada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w30QGcoZ_kv1",
    "outputId": "33ef848f-5c2a-40df-9894-3aa8e53fa1aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stCxtcXekQmf"
   },
   "source": [
    "Utilizamos la interfaz de configuración de sistemas de NVIDIA (NVIDIA System Management Interface) para conocer el estado de la tarjeta gráfica que vamos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7oDGUCF_mBK",
    "outputId": "001b2905-6f64-49ea-a8eb-6079d5215109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  6 20:15:07 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBfteA6XsqZD"
   },
   "source": [
    "Vemos cuál es el directorio de trabajo y su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QbLCHaCsvb-",
    "outputId": "4d9f0ab2-63ea-4f2e-ef4b-2be1f3a95b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "total 20\n",
      "drwxr-xr-x 1 root root 4096 Nov  6 20:14 .\n",
      "drwxr-xr-x 1 root root 4096 Nov  6 20:05 ..\n",
      "drwxr-xr-x 1 root root 4096 Nov  3 17:17 .config\n",
      "drwxr-xr-x 1 root root 4096 Oct 28 16:30 sample_data\n",
      "-rw-r--r-- 1 root root 1054 Nov  6 20:14 suma1.cu\n",
      "bin\t datalab  home\t lib64\topt   run   swift\t       tmp    var\n",
      "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t       tools\n",
      "content  etc\t  lib32  mnt\troot  srv   tensorflow-1.15.2  usr\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls -la\n",
    "!ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygCGApW0kmMa"
   },
   "source": [
    "Podemos ejecutar el código de ejemplo presente en la librería de Cuda que nos enumera las propiedades del dispositivo Cuda que existe en el sistema. Para ello, cambiamos de directorio a aquel donde se encuentra el código fuente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egav_e4ULqaQ",
    "outputId": "5bf4e9d5-c172-4806-b58c-1a71bade97ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-10.1/samples/1_Utilities/deviceQuery\n"
     ]
    }
   ],
   "source": [
    "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_heYpiyk_ow"
   },
   "source": [
    "El programa no se encuentra compilado, pero provee de un makefile para su fácil compilación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6sfqdvQLtAX",
    "outputId": "5b761de7-de85-4c5b-f446-354f268402b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-10.1/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery.o -c deviceQuery.cpp\n",
      "/usr/local/cuda-10.1/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery deviceQuery.o \n",
      "mkdir -p ../../bin/x86_64/linux/release\n",
      "cp deviceQuery ../../bin/x86_64/linux/release\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuXDl-JflIfY"
   },
   "source": [
    "Si ejecutamos el programa, obtenemos información interesante, como que el número máximo de threads por bloque que podemos utilizar es 1024:\n",
    "```\n",
    "Maximum number of threads per block: 1024\n",
    "```\n",
    "También vemos la dimensión máxima que podemos dar a cada dimensión de bloque y grid:\n",
    "```\n",
    "Max dimension size of a thread block (x,y,z): (1024, 1024, 64),\n",
    "Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKGfxLn7Lwje",
    "outputId": "8ceb6ec1-f8df-493b-f5c9-1ac9973127de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./deviceQuery Starting...\n",
      "\n",
      " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
      "\n",
      "Detected 1 CUDA Capable device(s)\n",
      "\n",
      "Device 0: \"Tesla T4\"\n",
      "  CUDA Driver Version / Runtime Version          10.1 / 10.1\n",
      "  CUDA Capability Major/Minor version number:    7.5\n",
      "  Total amount of global memory:                 15080 MBytes (15812263936 bytes)\n",
      "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
      "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
      "  Memory Clock rate:                             5001 Mhz\n",
      "  Memory Bus Width:                              256-bit\n",
      "  L2 Cache Size:                                 4194304 bytes\n",
      "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
      "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
      "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
      "  Total amount of constant memory:               65536 bytes\n",
      "  Total amount of shared memory per block:       49152 bytes\n",
      "  Total number of registers available per block: 65536\n",
      "  Warp size:                                     32\n",
      "  Maximum number of threads per multiprocessor:  1024\n",
      "  Maximum number of threads per block:           1024\n",
      "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
      "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
      "  Maximum memory pitch:                          2147483647 bytes\n",
      "  Texture alignment:                             512 bytes\n",
      "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
      "  Run time limit on kernels:                     No\n",
      "  Integrated GPU sharing Host Memory:            No\n",
      "  Support host page-locked memory mapping:       Yes\n",
      "  Alignment requirement for Surfaces:            Yes\n",
      "  Device has ECC support:                        Enabled\n",
      "  Device supports Unified Addressing (UVA):      Yes\n",
      "  Device supports Compute Preemption:            Yes\n",
      "  Supports Cooperative Kernel Launch:            Yes\n",
      "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
      "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
      "  Compute Mode:\n",
      "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
      "\n",
      "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 1\n",
      "Result = PASS\n"
     ]
    }
   ],
   "source": [
    "!./deviceQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDLZ98eZugMy"
   },
   "source": [
    "Finalmente, creamos un directorio de trabajo y entramos en él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rR5GMtllujlE",
    "outputId": "50e72640-8ddf-4046-f93f-edc85d1ce6c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/workcuda\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /content/workcuda\n",
    "%cd /content/workcuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2CtfWTcAASW"
   },
   "source": [
    "# Ejercicio 1: suma de vectores\n",
    "\n",
    "Disponemos de un código que realiza la suma de los elementos de un vector, sobreescribiendo el resultado en uno de ellos. Discutiremos varias versiones con distintos enfoques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7BxTkfPwSU2"
   },
   "source": [
    "## Suma en CPU\n",
    "En primer lugar escribimos un código para hacer la suma en CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTxHWXipwjBx",
    "outputId": "2b2704a9-8bd7-4b11-fdf1-8eb568ffa058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma0.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma0.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "void add(int n, float *x, float *y) {\n",
    "  for (int i=0; i < n; i++ ){\n",
    "    y[i]=x[i]+y[i];\n",
    "  }\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "  int N = 1 <<20; // N = 2^20 = 1024*1024= 1.048.576\n",
    "  float *x = new float[N];\n",
    "  float *y = new float[N];\n",
    "\n",
    "  // Medir tiempos\n",
    "  cudaEvent_t start, stop;\n",
    "  cudaEventCreate(&start);\n",
    "  cudaEventCreate(&stop);\n",
    "  \n",
    "  // Rellenar vectores\n",
    "  for (int i =0; i < N; i++ ){\n",
    "    x[i]= 1.0f;\n",
    "    y[i]= 2.0f;\n",
    "  }\n",
    "  \n",
    "  cudaEventRecord(start);\n",
    "\n",
    "  // Sumar elementos\n",
    "  add(N, x, y);\n",
    "\n",
    "  cudaEventRecord(stop);\n",
    "  cudaEventSynchronize(stop);\n",
    "  \n",
    "  // Calcular errores\n",
    "  float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "  for (int i=0; i <N; i++){\n",
    "    maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "    if (y[i] != 3.0) contError++;\n",
    "  }\n",
    "\n",
    "  float milliseconds = 0;\n",
    "  cudaEventElapsedTime(&milliseconds, start, stop);\n",
    "  std::cout << \"Elapsed Time (msecs): \" <<milliseconds << std::endl;\n",
    "\n",
    "  // Mostrar resultados\n",
    "  std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
    "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    "  // Limpieza\n",
    "  delete [] x;\n",
    "  delete [] y;\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad6cpwN1USKW"
   },
   "source": [
    "Compilamos y ejecutamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdmc_m4YUQ6a",
    "outputId": "104df6cb-c086-4544-9110-45e33a0bbbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time (msecs): 3.58131\n",
      "Suma de 1048576 elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma0.cu -o suma0 -lcudadevrt\n",
    "!./suma0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM9BmTgEU5pY"
   },
   "source": [
    "Vemos que, como esperábamos, se suman todos los elementos sin errores, y el tiempo de ejecución es de unos 3-4 ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rVyeFJ1YQWw"
   },
   "source": [
    "## Suma en GPU con data race\n",
    "\n",
    "Vamos a programar una versión preliminar que se ejecuta en GPU, simplemente convirtiendo la versión CPU de forma \"ingenua\". Definimos como constantes globales el número de threads y el número de bloques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLcHtYIfYPqI",
    "outputId": "86eaf8ec-968c-4d5f-fd1c-340167475667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting suma1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma1.cu\n",
    "\n",
    "#define THREADS 1\n",
    "#define BLOCKS 1\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "__global__ void add(int n, float *x, float *y) {\n",
    "  for (int i =0; i < n; i++ ){\n",
    "    y[i]=x[i]+y[i];\n",
    "  }\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "  int N = 1 <<20;\n",
    "  float *x; \n",
    "  float *y;\n",
    "\n",
    "  cudaMallocManaged(&x, N*sizeof(float));\n",
    "  cudaMallocManaged(&y, N*sizeof(float));\n",
    "  \n",
    "  for (int i =0; i < N; i++ ){\n",
    "    x[i]= 1.0f;\n",
    "    y[i]= 2.0f;\n",
    "  }\n",
    "\n",
    "  add<<<BLOCKS,THREADS>>>(N, x, y);\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "  for (int i=0; i <N; i++){\n",
    "    maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "    if (y[i] != 3.0) contError++;\n",
    "  }\n",
    "\n",
    "  std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
    "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "  cudaFree (x);\n",
    "  cudaFree (y);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWqcAgflaD1M"
   },
   "source": [
    "Compilamos y ejecutamos el programa tal cual, aprovechando y obteniendo la información del *profiler* para medir tiempos. Al dejar 1 bloque y 1 thread, estamos haciendo una ejecución en GPU pero en serie, sin aprovechar el paralelismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJeIcq_qaJwx",
    "outputId": "d5153758-160d-401e-bb96-9f34f6c3fd3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==421== NVPROF is profiling process 421, command: ./suma1\n",
      "Suma de 1048576 elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==421== Profiling application: ./suma1\n",
      "==421== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  126.84ms         1  126.84ms  126.84ms  126.84ms  add(int, float*, float*)\n",
      "      API calls:   61.84%  207.56ms         2  103.78ms  35.829us  207.52ms  cudaMallocManaged\n",
      "                   37.80%  126.85ms         1  126.85ms  126.85ms  126.85ms  cudaDeviceSynchronize\n",
      "                    0.16%  538.64us         2  269.32us  260.63us  278.01us  cudaFree\n",
      "                    0.11%  381.05us         1  381.05us  381.05us  381.05us  cuDeviceTotalMem\n",
      "                    0.05%  183.59us        97  1.8920us     164ns  84.451us  cuDeviceGetAttribute\n",
      "                    0.02%  51.969us         1  51.969us  51.969us  51.969us  cudaLaunchKernel\n",
      "                    0.01%  29.667us         1  29.667us  29.667us  29.667us  cuDeviceGetName\n",
      "                    0.01%  17.313us         1  17.313us  17.313us  17.313us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.0010us         3     667ns     191ns  1.3200us  cuDeviceGetCount\n",
      "                    0.00%  1.1830us         2     591ns     395ns     788ns  cuDeviceGet\n",
      "                    0.00%     288ns         1     288ns     288ns     288ns  cuDeviceGetUuid\n",
      "\n",
      "==421== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  816.7360us  Host To Device\n",
      "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  363.2320us  Device To Host\n",
      "      12         -         -         -           -  3.156160ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma1.cu -o suma1 -lcudadevrt\n",
    "!nvprof ./suma1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7IFUgPIcSBw"
   },
   "source": [
    "Vemos que la suma acaba sin errores, pero tarda más de 120 ms, unas 40 veces más que en CPU. Para intentar reducir este tiempo de ejecución, introducimos primero un paralelismo de threads, empleando 256 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egasdS5scReF",
    "outputId": "9ab52a64-0c7e-4dc6-edc6-1dfb21c52d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==604== NVPROF is profiling process 604, command: ./suma1\n",
      "Suma de 1048576 elementos\n",
      "Número de Errores: 2445\n",
      "Max error: 2\n",
      "==604== Profiling application: ./suma1\n",
      "==604== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  293.21ms         1  293.21ms  293.21ms  293.21ms  add(int, float*, float*)\n",
      "      API calls:   57.93%  293.23ms         1  293.23ms  293.23ms  293.23ms  cudaDeviceSynchronize\n",
      "                   41.83%  211.74ms         2  105.87ms  35.393us  211.71ms  cudaMallocManaged\n",
      "                    0.11%  552.91us         2  276.45us  268.46us  284.45us  cudaFree\n",
      "                    0.08%  400.16us         1  400.16us  400.16us  400.16us  cuDeviceTotalMem\n",
      "                    0.03%  166.71us        97  1.7180us     151ns  75.741us  cuDeviceGetAttribute\n",
      "                    0.01%  43.704us         1  43.704us  43.704us  43.704us  cudaLaunchKernel\n",
      "                    0.01%  33.707us         1  33.707us  33.707us  33.707us  cuDeviceGetName\n",
      "                    0.00%  3.0610us         1  3.0610us  3.0610us  3.0610us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.7440us         3     581ns     180ns  1.0580us  cuDeviceGetCount\n",
      "                    0.00%  1.3890us         2     694ns     443ns     946ns  cuDeviceGet\n",
      "                    0.00%     262ns         1     262ns     262ns     262ns  cuDeviceGetUuid\n",
      "\n",
      "==604== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  812.3520us  Host To Device\n",
      "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  353.6320us  Device To Host\n",
      "      12         -         -         -           -  3.626304ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define THREADS/c\\#define THREADS 256' suma1.cu\n",
    "!sed -i '/#define BLOCKS/c\\#define BLOCKS 1' suma1.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma1.cu -o suma1 -lcudadevrt\n",
    "!nvprof ./suma1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44LbFGJmgNzw"
   },
   "source": [
    "Vemos que, contrario a nuestras pretensiones, la suma ha tardado más, y con muchos más errores. El hecho de que tarde más se debe a que en cada thread estamos haciendo $N$ sumas, lo que introduce un cierto *overhead*. En cuanto a los errores, se deben a que, como cada thread accede a la memoria global y modifica el contenido del vector `y`, se producirán errores siempre que una hebra lea un valor después de que otra haya sobreescrito esa posición. Esto es lo que se conoce como *condición de carrera* o *data race*, y el hecho de que haya más o menos errores será aleatorio en función de los tiempos de lectura y escritura de las hebras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KX8M96qHlADT"
   },
   "source": [
    "Podemos intentar hacer también un paralelismo de bloques, fijando 256 bloques con un único thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaIEop_Vgc6-",
    "outputId": "61f3f54b-bbe9-473d-ee48-40199f86f55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==656== NVPROF is profiling process 656, command: ./suma1\n",
      "Suma de 1048576 elementos\n",
      "Número de Errores: 1048573\n",
      "Max error: 234\n",
      "==656== Profiling application: ./suma1\n",
      "==656== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  270.85ms         1  270.85ms  270.85ms  270.85ms  add(int, float*, float*)\n",
      "      API calls:   55.66%  270.87ms         1  270.87ms  270.87ms  270.87ms  cudaDeviceSynchronize\n",
      "                   44.10%  214.64ms         2  107.32ms  35.790us  214.60ms  cudaMallocManaged\n",
      "                    0.12%  580.06us         2  290.03us  278.96us  301.10us  cudaFree\n",
      "                    0.07%  360.46us         1  360.46us  360.46us  360.46us  cuDeviceTotalMem\n",
      "                    0.03%  150.23us        97  1.5480us     141ns  63.245us  cuDeviceGetAttribute\n",
      "                    0.01%  39.951us         1  39.951us  39.951us  39.951us  cudaLaunchKernel\n",
      "                    0.01%  35.075us         1  35.075us  35.075us  35.075us  cuDeviceGetName\n",
      "                    0.00%  3.3900us         1  3.3900us  3.3900us  3.3900us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.8200us         3     606ns     179ns  1.0950us  cuDeviceGetCount\n",
      "                    0.00%  1.1850us         2     592ns     372ns     813ns  cuDeviceGet\n",
      "                    0.00%     260ns         1     260ns     260ns     260ns  cuDeviceGetUuid\n",
      "\n",
      "==656== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  826.4320us  Host To Device\n",
      "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  353.6000us  Device To Host\n",
      "      19         -         -         -           -  4.263424ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define THREADS/c\\#define THREADS 1' suma1.cu\n",
    "!sed -i '/#define BLOCKS/c\\#define BLOCKS 256' suma1.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma1.cu -o suma1 -lcudadevrt\n",
    "!nvprof ./suma1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ak5b8LtDlDtE"
   },
   "source": [
    "En este caso el tiempo de ejecución es similar al caso de paralelismo de threads. Lo que sí podemos destacar es que se producen errores en casi todas las posiciones del vector, de forma consistente en varias ejecuciones. Esto puede deberse a que, en el caso de varios bloques, solo se ejecuta cada vez un *warp* dentro de cada bloque, y en nuestro caso estos *warps* constarían de un único thread, por lo que es más difícil evitar las condiciones de carrera. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48cKzJ7wOSJ9"
   },
   "source": [
    "## Suma en GPU sin data race y combinando bloques y threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stH50xXTOWRv"
   },
   "source": [
    "Vamos a modificar el código para evitar las condiciones de carrera y producir un resultado correcto en todos los casos. Para ello, necesitamos que cada hebra (o bloque) procese únicamente unas ciertas posiciones del vector, de forma que no haya conflictos y que se procese el vector completo. Para ello usamos las variables `threadIdx.x`, `blockIdx.x`, `blockDim.x` y `gridDim.x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7eBitm8Ozer",
    "outputId": "64259321-6744-489c-e2cb-97ae7c3007b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting suma2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma2.cu\n",
    "\n",
    "#define N (1<<20)\n",
    "#define THREADS 256\n",
    "#define BLOCKS 1\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "__global__ void add_all(int n, float *x, float *y) {\n",
    "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  if (i < n)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "__global__ void add_threads(int n, float *x, float *y) {\n",
    "  for (int i = threadIdx.x; i < n; i += blockDim.x)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "__global__ void add_blocks(int n, float *x, float *y) {\n",
    "  for (int i = blockIdx.x; i < n; i += gridDim.x)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "  float *x; \n",
    "  float *y;\n",
    "\n",
    "  cudaMallocManaged(&x, N*sizeof(float));\n",
    "  cudaMallocManaged(&y, N*sizeof(float));\n",
    "  \n",
    "  for (int i =0; i < N; i++ ){\n",
    "    x[i]= 1.0f;\n",
    "    y[i]= 2.0f;\n",
    "  }\n",
    "\n",
    "#if BLOCKS > 0 && THREADS == 1\n",
    "  add_blocks<<<BLOCKS,THREADS>>>(N, x, y);\n",
    "#elif BLOCKS == 1 && THREADS > 0\n",
    "  add_threads<<<BLOCKS,THREADS>>>(N, x, y);\n",
    "#else\n",
    "  add_all<<<BLOCKS,THREADS>>>(N, x, y);\n",
    "#endif\n",
    "\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "  for (int i=0; i <N; i++){\n",
    "    maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "    if (y[i] != 3.0) contError++;\n",
    "  }\n",
    "\n",
    "  std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
    "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "  cudaFree (x);\n",
    "  cudaFree (y);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knkc7zyk-uJU"
   },
   "source": [
    "Probamos ahora a lanzar el kernel tanto con 1 bloque y 256 threads como con 256 threads y una sola hebra por bloque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HSzy02K-1P2",
    "outputId": "29b3e283-e204-4cd9-a15c-146ec5e40360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==998== NVPROF is profiling process 998, command: ./suma2\n",
      "Suma de 1048576 elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==998== Profiling application: ./suma2\n",
      "==998== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  4.4753ms         1  4.4753ms  4.4753ms  4.4753ms  add_threads(int, float*, float*)\n",
      "      API calls:   97.25%  198.21ms         2  99.106ms  35.125us  198.18ms  cudaMallocManaged\n",
      "                    2.20%  4.4859ms         1  4.4859ms  4.4859ms  4.4859ms  cudaDeviceSynchronize\n",
      "                    0.27%  550.59us         2  275.29us  249.98us  300.61us  cudaFree\n",
      "                    0.17%  344.45us         1  344.45us  344.45us  344.45us  cuDeviceTotalMem\n",
      "                    0.07%  149.57us        97  1.5410us     132ns  57.314us  cuDeviceGetAttribute\n",
      "                    0.02%  45.544us         1  45.544us  45.544us  45.544us  cudaLaunchKernel\n",
      "                    0.01%  27.627us         1  27.627us  27.627us  27.627us  cuDeviceGetName\n",
      "                    0.00%  3.0630us         1  3.0630us  3.0630us  3.0630us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.7450us         3     581ns     128ns  1.2150us  cuDeviceGetCount\n",
      "                    0.00%  1.2490us         2     624ns     306ns     943ns  cuDeviceGet\n",
      "                    0.00%     279ns         1     279ns     279ns     279ns  cuDeviceGetUuid\n",
      "\n",
      "==998== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  808.6720us  Host To Device\n",
      "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  362.1120us  Device To Host\n",
      "      12         -         -         -           -  2.762496ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define THREADS/c\\#define THREADS 256' suma2.cu\n",
    "!sed -i '/#define BLOCKS/c\\#define BLOCKS 1' suma2.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
    "!nvprof ./suma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJbWjlIWBmos",
    "outputId": "d2f7dd33-9ac5-4d54-ebf6-45798c135f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==1048== NVPROF is profiling process 1048, command: ./suma2\n",
      "Suma de 1048576 elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==1048== Profiling application: ./suma2\n",
      "==1048== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  4.1395ms         1  4.1395ms  4.1395ms  4.1395ms  add_blocks(int, float*, float*)\n",
      "      API calls:   97.43%  198.91ms         2  99.456ms  31.638us  198.88ms  cudaMallocManaged\n",
      "                    2.03%  4.1477ms         1  4.1477ms  4.1477ms  4.1477ms  cudaDeviceSynchronize\n",
      "                    0.27%  542.89us         2  271.45us  268.33us  274.56us  cudaFree\n",
      "                    0.17%  346.14us         1  346.14us  346.14us  346.14us  cuDeviceTotalMem\n",
      "                    0.07%  142.00us        97  1.4630us     134ns  62.884us  cuDeviceGetAttribute\n",
      "                    0.02%  36.952us         1  36.952us  36.952us  36.952us  cudaLaunchKernel\n",
      "                    0.01%  28.646us         1  28.646us  28.646us  28.646us  cuDeviceGetName\n",
      "                    0.00%  3.0430us         1  3.0430us  3.0430us  3.0430us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9560us         3     652ns     142ns  1.3210us  cuDeviceGetCount\n",
      "                    0.00%  1.1320us         2     566ns     271ns     861ns  cuDeviceGet\n",
      "                    0.00%     280ns         1     280ns     280ns     280ns  cuDeviceGetUuid\n",
      "\n",
      "==1048== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  807.0400us  Host To Device\n",
      "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  363.8400us  Device To Host\n",
      "      12         -         -         -           -  2.551584ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define THREADS/c\\#define THREADS 1' suma2.cu\n",
    "!sed -i '/#define BLOCKS/c\\#define BLOCKS 256' suma2.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
    "!nvprof ./suma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XuiZgwmBuXh"
   },
   "source": [
    "Vemos que en ambos casos todas las sumas se realizan correctamente (hay 0 errores), y se reduce notablemente el tiempo de ejecución de la suma, llegando hasta los 4 ms. \n",
    "\n",
    "Podemos probar, por ejemplo, a aumentar el número de threads, y vemos cómo se reduce aún más el tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mss-cX6wCJg6",
    "outputId": "3fa05946-3cc2-47f2-a13a-976decf4720a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==1100== NVPROF is profiling process 1100, command: ./suma2\n",
      "Suma de 1048576 elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==1100== Profiling application: ./suma2\n",
      "==1100== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.5332ms         1  3.5332ms  3.5332ms  3.5332ms  add_threads(int, float*, float*)\n",
      "      API calls:   97.72%  200.43ms         2  100.22ms  36.977us  200.40ms  cudaMallocManaged\n",
      "                    1.73%  3.5433ms         1  3.5433ms  3.5433ms  3.5433ms  cudaDeviceSynchronize\n",
      "                    0.26%  527.04us         2  263.52us  257.99us  269.05us  cudaFree\n",
      "                    0.19%  385.01us         1  385.01us  385.01us  385.01us  cuDeviceTotalMem\n",
      "                    0.07%  144.75us        97  1.4920us     132ns  60.551us  cuDeviceGetAttribute\n",
      "                    0.02%  39.303us         1  39.303us  39.303us  39.303us  cudaLaunchKernel\n",
      "                    0.02%  31.175us         1  31.175us  31.175us  31.175us  cuDeviceGetName\n",
      "                    0.00%  3.9100us         1  3.9100us  3.9100us  3.9100us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.8160us         3     605ns     158ns  1.2220us  cuDeviceGetCount\n",
      "                    0.00%  1.5000us         2     750ns     305ns  1.1950us  cuDeviceGet\n",
      "                    0.00%     252ns         1     252ns     252ns     252ns  cuDeviceGetUuid\n",
      "\n",
      "==1100== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  822.1760us  Host To Device\n",
      "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  363.7760us  Device To Host\n",
      "      15         -         -         -           -  3.029344ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define THREADS/c\\#define THREADS 1024' suma2.cu\n",
    "!sed -i '/#define BLOCKS/c\\#define BLOCKS 1' suma2.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
    "!nvprof ./suma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmyV4CtLGm1v"
   },
   "source": [
    "Para la última versión, utilizamos tanto bloques como threads. La idea aquí es precalcular el número necesario de bloques dado un número de threads, para que todos los elementos se procesen de forma adecuada y sin errores. Si $TPB$ es el número de threads por bloque y $N$ es el tamaño del vector a sumar, el número de bloques óptimo, $NB$, viene dado por:\n",
    "\n",
    "$$NB=\\frac{N+TPB-1}{TPB}.$$\n",
    "\n",
    "Es decir, dividimos el número de elementos a procesar entre el número de threads por bloque, teniendo en cuenta que es posible que haya que redondear si $N$ no es una potencia de $TPB$. En el propio kernel añadimos una comprobación `if (i < n)` para asegurarnos que no accedemos a posiciones ilegales del vector.\n",
    "\n",
    "De esta forma, si $N$ es multiplo de $TPB$, se tiene que\n",
    "\n",
    "$$\n",
    "NB=\\frac{N + TPB - 1}{TPB} = \\frac{N}{TPB} + 1 - \\frac{1}{TPB} = K + 1 -\\frac{1}{TPB},\n",
    "$$\n",
    "\n",
    "lo cual tras transformarlo a entero resultaría en $NB=K = N/TPB \\in \\mathbb{N}$. En caso de no ser múltiplos, $N$ se descompone como $N_1 + N_2$, ambos enteros, donde $N_1$ sí es multiplo de $TPB$ y $1 \\leq N_2 < TPB$. En este caso:\n",
    "\n",
    "$$\n",
    "\\frac{N + TPB - 1}{TPB} = \\frac{N_1}{TPB} + \\frac{N_2}{TPB} + 1 - \\frac{1}{TPB} = K + 1 + \\frac{N_2}{TPB} -\\frac{1}{TPB}.\n",
    "$$\n",
    "\n",
    "Pero por por ser $1 \\leq N_2 < TPB$ y $N_2 \\in \\mathbb{N}$, tenemos: \n",
    "$$\n",
    "0 \\leq \\frac{N_2}{TPB} -\\frac{1}{TPB} < TPB.\n",
    "$$\n",
    "\n",
    "Así, al convertir a entero obtenemos en total $NB=K + 1 = \\dfrac{N_1}{TPB} + 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HmQ_wRKmE1B2",
    "outputId": "c8bb240f-3048-4711-fe25-e534fa912f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==1272== NVPROF is profiling process 1272, command: ./suma2\n",
      "Suma de 1048576 elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==1272== Profiling application: ./suma2\n",
      "==1272== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  2.8820ms         1  2.8820ms  2.8820ms  2.8820ms  add_all(int, float*, float*)\n",
      "      API calls:   98.05%  201.23ms         2  100.62ms  34.606us  201.20ms  cudaMallocManaged\n",
      "                    1.43%  2.9288ms         1  2.9288ms  2.9288ms  2.9288ms  cudaDeviceSynchronize\n",
      "                    0.25%  521.81us         2  260.91us  253.91us  267.90us  cudaFree\n",
      "                    0.16%  332.80us         1  332.80us  332.80us  332.80us  cuDeviceTotalMem\n",
      "                    0.07%  142.79us        97  1.4720us     129ns  58.247us  cuDeviceGetAttribute\n",
      "                    0.02%  35.906us         1  35.906us  35.906us  35.906us  cudaLaunchKernel\n",
      "                    0.01%  25.355us         1  25.355us  25.355us  25.355us  cuDeviceGetName\n",
      "                    0.00%  3.1210us         1  3.1210us  3.1210us  3.1210us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.2250us         3     741ns     146ns  1.6150us  cuDeviceGetCount\n",
      "                    0.00%  1.2680us         2     634ns     258ns  1.0100us  cuDeviceGet\n",
      "                    0.00%     254ns         1     254ns     254ns     254ns  cuDeviceGetUuid\n",
      "\n",
      "==1272== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "     136  60.234KB  4.0000KB  956.00KB  8.000000MB  1.022080ms  Host To Device\n",
      "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  361.9200us  Device To Host\n",
      "      11         -         -         -           -  2.833856ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define THREADS/c\\#define THREADS 256' suma2.cu\n",
    "!sed -i '/#define BLOCKS/c\\#define BLOCKS ((N + THREADS - 1) / THREADS)' suma2.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
    "!nvprof ./suma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seHzLBHHFO2W"
   },
   "source": [
    "Vemos que seguimos sin obtener errores, y el tiempo de ejecución es aún más bajo, menos de 3 ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXhdA6K4Tm6A"
   },
   "source": [
    "### Mejora en el kernel\n",
    "\n",
    "En el código anterior podríamos haber considerado la siguiente modificación del kernel para sumar los elementos del vector usando bloques y threads:\n",
    "\n",
    "```python\n",
    "__global__ void add(int n, float *x, float *y) {\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "```\n",
    "\n",
    "Como podemos ver en [el blog de Nvidia](https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/), utilizar esta estrategia tiene una serie de ventajas, siendo la principal de ellas que podemos manejar vectores de tamaños arbitrarios, y no estaríamos limitados por el máximo tamaño de grid en la dimensión `x` (que en nuestro caso vimos antes que es 2147483647)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COrmRBS0GBqw"
   },
   "source": [
    "### Otra operación matemática con más elementos\n",
    "\n",
    "Finalmente hacemos una prueba cambiando la complejidad de la operación matemática, por ejemplo a la división. También aumentamos el número de elementos del vector por ejemplo a $2^{30}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X89gM5I_GcUn",
    "outputId": "6cb74b75-4dc1-4ca2-c0d9-237f8f818c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting div.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile div.cu\n",
    "\n",
    "#define N (1<<30)\n",
    "#define THREADS 256\n",
    "#define BLOCKS ((N + THREADS - 1)/THREADS)\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "__global__ void div(int n, float *x, float *y) {\n",
    "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  if (i < n)\n",
    "    y[i] = x[i] / y[i];\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "  float *x; \n",
    "  float *y;\n",
    "\n",
    "  cudaMallocManaged(&x, N*sizeof(float));\n",
    "  cudaMallocManaged(&y, N*sizeof(float));\n",
    "  \n",
    "  for (int i =0; i < N; i++ ){\n",
    "    x[i]= 1.0f;\n",
    "    y[i]= 2.0f;\n",
    "  }\n",
    "\n",
    "  div<<<BLOCKS,THREADS>>>(N, x, y);\n",
    "\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "  for (int i=0; i <N; i++){\n",
    "    maxError=fmax(maxError,fabs(y[i]-0.5f));\n",
    "    if (y[i] != 0.5) contError++;\n",
    "  }\n",
    "\n",
    "  std::cout << \"División de \" << N << \" elementos\" << std::endl;\n",
    "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
    "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "  cudaFree (x);\n",
    "  cudaFree (y);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kJsziWwG3T-",
    "outputId": "d1acc851-4b81-42af-bedf-e39539dc79ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==1454== NVPROF is profiling process 1454, command: ./div\n",
      "División de 1073741824 elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==1454== Profiling application: ./div\n",
      "==1454== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.01753s         1  3.01753s  3.01753s  3.01753s  div(int, float*, float*)\n",
      "      API calls:   80.45%  3.01755s         1  3.01755s  3.01755s  3.01755s  cudaDeviceSynchronize\n",
      "                   13.87%  520.12ms         2  260.06ms  219.43ms  300.70ms  cudaFree\n",
      "                    5.66%  212.39ms         2  106.19ms  59.086us  212.33ms  cudaMallocManaged\n",
      "                    0.01%  411.82us         1  411.82us  411.82us  411.82us  cuDeviceTotalMem\n",
      "                    0.00%  158.31us        97  1.6320us     153ns  66.770us  cuDeviceGetAttribute\n",
      "                    0.00%  59.387us         1  59.387us  59.387us  59.387us  cudaLaunchKernel\n",
      "                    0.00%  31.950us         1  31.950us  31.950us  31.950us  cuDeviceGetName\n",
      "                    0.00%  3.2980us         1  3.2980us  3.2980us  3.2980us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.8070us         3     602ns     193ns  1.1530us  cuDeviceGetCount\n",
      "                    0.00%  1.4260us         2     713ns     367ns  1.0590us  cuDeviceGet\n",
      "                    0.00%     329ns         1     329ns     329ns     329ns  cuDeviceGetUuid\n",
      "\n",
      "==1454== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "  127618  63.273KB  4.0000KB  0.9961MB  7.700821GB  991.1141ms  Host To Device\n",
      "   24576  170.67KB  4.0000KB  0.9961MB  4.000000GB  368.8712ms  Device To Host\n",
      "   11933         -         -         -           -   3.127564s  Gpu page fault groups\n",
      "Total CPU Page faults: 36864\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true div.cu -o div -lcudadevrt\n",
    "!nvprof ./div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYLHwWRFHI6m"
   },
   "source": [
    "Seguimos sin tener errores, aunque ahora el tiempo de las divisiones es mayor, llegando a los 3 s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hBoDHP-twyR"
   },
   "source": [
    "# Ejercicio 2: suma de matrices\n",
    "\n",
    "En este ejercicio extendemos la suma de vectores a sumas de matrices de dimensiones arbitrarias $R\\times C$. La idea es la misma que antes, implementando directamente la versión que trabaja con bloques y threads sin condiciones de carrera. Realizamos una estructura bidimensional de bloques y threads, de forma que cada thread procese la posición que le corresponde de las matrices de entrada. Es decir, el thread $(i, j)$ (en coordenadas de grid) realiza la suma $x[i, j] + y[i, j]$.\n",
    "\n",
    "Para elegir la dimensión de los bloques, consideramos bloques cuadrados de $8\\times 8$ threads. Hacemos esto para aprovechar al máximo la granularidad de bloques, teniendo en cuenta que, gracias al programa `deviceQuery`, sabemos que:\n",
    "\n",
    "- El número máximo de threads por SM es 1024.\n",
    "- El número máximo de threads por bloque es 1024.\n",
    "- El número máximo de bloques residentes en un SM en cualquier instante es de 16. Esto lo sabemos porque la capacidad de cómputo de la gráfica usada aquí es la de la versión 7.5, y según la [información de versiones de CUDA](https://en.wikipedia.org/wiki/CUDA#Version_features_and_specifications), a esta le corresponden 16 bloques por SM como máximo.\n",
    "\n",
    "Así, con bloques de $TPB=8\\times 8=64$ threads podremos llegar al máximo de 16 bloques por SM sin violar ninguna restricción y maximizando el número de threads por SM. Notamos que también podríamos haber usado bloques de $16\\times 16$ y de $32\\times 32$ sin violar las restricciones. El número óptimo de threads por bloque habría que buscarlo viendo las estadísticas de ocupación y el rendimiento del kernel. En general, cuando no se hace uso de memoria compartida, es una buena estrategia intentar maximizar la ocupación de la GPU, lo que conseguimos maximizando el número de bloques residentes.\n",
    "\n",
    "A la hora de configurar el grid de bloques, hacemos lo análogo a lo que hicimos para sumar vectores, pero ahora lo hacemos en cada dimensión. Ajustamos el número de bloques a $(R+63)/64$ en la coordenada `x` y a $(C+63)/64$ en la coordenada `y`. A la hora de programar el kernel tendremos que tener cuidado de no acceder a posiciones ilegales del vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMnDmBzfvAYH",
    "outputId": "355edf91-8327-406d-d09d-38f9ef8d9989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting suma_mat.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma_mat.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "#define R 1024\n",
    "#define C 1024\n",
    "#define TPB 8  \n",
    "\n",
    "__global__ void add_matrices(int r, int c, float *x, float *y) {\n",
    "  int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
    "  int index = i*c + j;\n",
    "  \n",
    "  if (i < r && j < c)\n",
    "    y[index] = x[index] + y[index];\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "  float *x; \n",
    "  float *y;\n",
    "\n",
    "  cudaMallocManaged(&x, C*R*sizeof(float));\n",
    "  cudaMallocManaged(&y, C*R*sizeof(float));\n",
    "  \n",
    "  // Inicializamos los datos\n",
    "  for (int i =0; i < R; i++ ){\n",
    "      for (int j = 0; j < C; j++){\n",
    "          x[i*C + j] = 1.0f;\n",
    "          y[i*C + j] = 2.0f;\n",
    "      }\n",
    "  }\n",
    "\n",
    "  // Definimos la dimensión del grid \n",
    "  dim3 dimGrid ((R + TPB - 1)/TPB , (C + TPB - 1)/TPB, 1);\n",
    "  \n",
    "  // Definimos la dimensión del bloque\n",
    "  dim3 dimBlock(TPB, TPB, 1);\n",
    "\n",
    "  // Lanzamos la función en el dispositivo.\n",
    "  add_matrices<<<dimGrid, dimBlock>>>(R, C, x, y);\n",
    "\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "  for (int i=0; i <R; i++){\n",
    "    for (int j =0; j < C; j++) {\n",
    "      maxError=fmax(maxError,fabs(y[i*C + j]-3.0f));\n",
    "      if (y[i*C+j] != 3.0f) contError++;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  std::cout << \"Suma de \" << R*C << \" elementos de las matrices\" << std::endl;\n",
    "  std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
    "  std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "  cudaFree (x);\n",
    "  cudaFree (y);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLEkNjzgGI0y"
   },
   "source": [
    "Probamos en primer lugar a sumar matrices cuadradas de orden una potencia de 2 (en este caso $2^{10}$). Vemos que se obtiene un resultado correcto en un tiempo razonable (unos 3 ms). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vtes1wA0vAYe",
    "outputId": "ebed0e84-e9fc-46d7-e76b-47c3690f710e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==980== NVPROF is profiling process 980, command: ./suma_mat\n",
      "Suma de 1048576 elementos de las matrices\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==980== Profiling application: ./suma_mat\n",
      "==980== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  2.6821ms         1  2.6821ms  2.6821ms  2.6821ms  add_matrices(int, int, float*, float*)\n",
      "      API calls:   98.24%  220.53ms         2  110.27ms  44.212us  220.49ms  cudaMallocManaged\n",
      "                    1.20%  2.6924ms         1  2.6924ms  2.6924ms  2.6924ms  cudaDeviceSynchronize\n",
      "                    0.27%  599.15us         2  299.58us  284.80us  314.35us  cudaFree\n",
      "                    0.18%  404.96us         1  404.96us  404.96us  404.96us  cuDeviceTotalMem\n",
      "                    0.08%  170.24us        97  1.7550us     153ns  67.461us  cuDeviceGetAttribute\n",
      "                    0.02%  50.403us         1  50.403us  50.403us  50.403us  cudaLaunchKernel\n",
      "                    0.01%  32.722us         1  32.722us  32.722us  32.722us  cuDeviceGetName\n",
      "                    0.00%  3.7700us         1  3.7700us  3.7700us  3.7700us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.0330us         3     677ns     179ns  1.3930us  cuDeviceGetCount\n",
      "                    0.00%  1.3130us         2     656ns     322ns     991ns  cuDeviceGet\n",
      "                    0.00%     288ns         1     288ns     288ns     288ns  cuDeviceGetUuid\n",
      "\n",
      "==980== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "     257  31.875KB  4.0000KB  512.00KB  8.000000MB  1.385984ms  Host To Device\n",
      "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  361.0560us  Device To Host\n",
      "       4         -         -         -           -  3.654464ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma_mat.cu -o suma_mat -lcudadevrt\n",
    "!nvprof ./suma_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfPobepCGXX6"
   },
   "source": [
    "Probamos ahora a sumar matrices que no sean cuadradas, e incluso que no tengan tamaño potencia de 2 en ninguna dimensión. Vemos que en todos los casos se obtiene un resultado correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPfCwXRnekzR",
    "outputId": "dd6de94c-e2b8-4367-c7a7-0bf8f4c216cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==128== NVPROF is profiling process 128, command: ./suma_mat\n",
      "Suma de 524288 elementos de las matrices\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==128== Profiling application: ./suma_mat\n",
      "==128== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  1.5789ms         1  1.5789ms  1.5789ms  1.5789ms  add_matrices(int, int, float*, float*)\n",
      "      API calls:   99.14%  290.24ms         2  145.12ms  33.220us  290.20ms  cudaMallocManaged\n",
      "                    0.54%  1.5880ms         1  1.5880ms  1.5880ms  1.5880ms  cudaDeviceSynchronize\n",
      "                    0.12%  363.23us         1  363.23us  363.23us  363.23us  cuDeviceTotalMem\n",
      "                    0.11%  324.79us         2  162.39us  160.01us  164.78us  cudaFree\n",
      "                    0.05%  157.45us        97  1.6230us     136ns  66.998us  cuDeviceGetAttribute\n",
      "                    0.02%  52.882us         1  52.882us  52.882us  52.882us  cudaLaunchKernel\n",
      "                    0.01%  32.516us         1  32.516us  32.516us  32.516us  cuDeviceGetName\n",
      "                    0.00%  3.5700us         1  3.5700us  3.5700us  3.5700us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.0570us         3     685ns     139ns  1.4160us  cuDeviceGetCount\n",
      "                    0.00%  1.8810us         2     940ns     322ns  1.5590us  cuDeviceGet\n",
      "                    0.00%     269ns         1     269ns     269ns     269ns  cuDeviceGetUuid\n",
      "\n",
      "==128== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "     134  30.566KB  4.0000KB  228.00KB  4.000000MB  851.4880us  Host To Device\n",
      "      12  170.67KB  4.0000KB  0.9961MB  2.000000MB  183.8720us  Device To Host\n",
      "       1         -         -         -           -  1.530848ms  Gpu page fault groups\n",
      "Total CPU Page faults: 18\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define R/c\\#define R 512' suma_mat.cu\n",
    "!sed -i '/#define C/c\\#define C 1024' suma_mat.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma_mat.cu -o suma_mat -lcudadevrt\n",
    "!nvprof ./suma_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EC_vLV54eyZG",
    "outputId": "697c402b-53f8-445e-d872-760b5604ca12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==178== NVPROF is profiling process 178, command: ./suma_mat\n",
      "Suma de 524288 elementos de las matrices\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==178== Profiling application: ./suma_mat\n",
      "==178== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  1.3979ms         1  1.3979ms  1.3979ms  1.3979ms  add_matrices(int, int, float*, float*)\n",
      "      API calls:   98.87%  204.45ms         2  102.23ms  36.438us  204.42ms  cudaMallocManaged\n",
      "                    0.69%  1.4287ms         1  1.4287ms  1.4287ms  1.4287ms  cudaDeviceSynchronize\n",
      "                    0.17%  342.15us         1  342.15us  342.15us  342.15us  cuDeviceTotalMem\n",
      "                    0.16%  328.54us         2  164.27us  151.29us  177.25us  cudaFree\n",
      "                    0.07%  152.22us        97  1.5690us     132ns  64.613us  cuDeviceGetAttribute\n",
      "                    0.02%  42.600us         1  42.600us  42.600us  42.600us  cudaLaunchKernel\n",
      "                    0.02%  31.840us         1  31.840us  31.840us  31.840us  cuDeviceGetName\n",
      "                    0.00%  3.4290us         1  3.4290us  3.4290us  3.4290us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9530us         3     651ns     154ns  1.3920us  cuDeviceGetCount\n",
      "                    0.00%  1.2490us         2     624ns     327ns     922ns  cuDeviceGet\n",
      "                    0.00%     299ns         1     299ns     299ns     299ns  cuDeviceGetUuid\n",
      "\n",
      "==178== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "     133  30.797KB  4.0000KB  648.00KB  4.000000MB  711.8080us  Host To Device\n",
      "      12  170.67KB  4.0000KB  0.9961MB  2.000000MB  177.6320us  Device To Host\n",
      "       1         -         -         -           -  1.350144ms  Gpu page fault groups\n",
      "Total CPU Page faults: 18\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define R/c\\#define R 1024' suma_mat.cu\n",
    "!sed -i '/#define C/c\\#define C 512' suma_mat.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma_mat.cu -o suma_mat -lcudadevrt\n",
    "!nvprof ./suma_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33tZLEY-e6ED",
    "outputId": "3a48fa08-8931-4a68-962c-aeb0fffe1e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==511== NVPROF is profiling process 511, command: ./suma_mat\n",
      "Suma de 887112 elementos de las matrices\n",
      "Número de Errores: 0\n",
      "Max error: 0\n",
      "==511== Profiling application: ./suma_mat\n",
      "==511== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  2.7285ms         1  2.7285ms  2.7285ms  2.7285ms  add_matrices(int, int, float*, float*)\n",
      "      API calls:   98.08%  207.58ms         2  103.79ms  57.027us  207.52ms  cudaMallocManaged\n",
      "                    1.39%  2.9448ms         1  2.9448ms  2.9448ms  2.9448ms  cudaDeviceSynchronize\n",
      "                    0.25%  521.64us         2  260.82us  249.86us  271.78us  cudaFree\n",
      "                    0.17%  355.07us         1  355.07us  355.07us  355.07us  cuDeviceTotalMem\n",
      "                    0.07%  146.81us        97  1.5130us     132ns  61.761us  cuDeviceGetAttribute\n",
      "                    0.03%  64.332us         1  64.332us  64.332us  64.332us  cudaLaunchKernel\n",
      "                    0.01%  30.328us         1  30.328us  30.328us  30.328us  cuDeviceGetName\n",
      "                    0.00%  3.2610us         1  3.2610us  3.2610us  3.2610us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.7090us         3     569ns     176ns  1.1010us  cuDeviceGetCount\n",
      "                    0.00%  1.1650us         2     582ns     331ns     834ns  cuDeviceGet\n",
      "                    0.00%     238ns         1     238ns     238ns     238ns  cuDeviceGetUuid\n",
      "\n",
      "==511== Unified Memory profiling result:\n",
      "Device \"Tesla T4 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "     316  21.949KB  4.0000KB  332.00KB  6.773438MB  1.589984ms  Host To Device\n",
      "      24  144.50KB  4.0000KB  0.9961MB  3.386719MB  321.9840us  Device To Host\n",
      "       3         -         -         -           -  3.414048ms  Gpu page fault groups\n",
      "Total CPU Page faults: 36\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define R/c\\#define R 999' suma_mat.cu\n",
    "!sed -i '/#define C/c\\#define C 888' suma_mat.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma_mat.cu -o suma_mat -lcudadevrt\n",
    "!nvprof ./suma_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LvhkbKTtz2F"
   },
   "source": [
    "# Ejercicio 3: Stencil1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDVz5Mh4vPUh"
   },
   "source": [
    "## Versión sin memoria compartida\n",
    "\n",
    "Programamos una versión de `stencil` con radio 3 sin usar memoria compartida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlz3mwX1vPUo",
    "outputId": "9ca75a90-bd04-423b-db53-c01c2a8c8b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stencil1d_v1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_v1.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) {\n",
    "    // Índice global de la posición central de los datos que va a usar el thread\n",
    "    int index = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    "\n",
    "    // Realizamos la operación del stencil\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS; offset <= RADIUS; offset++)\n",
    "        result += in[index + offset];\n",
    "\n",
    "    // Guardamos el resultado\n",
    "    out[index-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "  unsigned int i;\n",
    "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "  int *d_in, *d_out;\n",
    "\n",
    "  // Incializamos los datos en el host\n",
    "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "    // Con un valor de 1 y un radio de RADIUS, el array de resultados debería\n",
    "    // ser de 2*RADIUS+1\n",
    "    h_in[i] = 1; \n",
    "\n",
    "  // Reservamos memoria en el dispositivo\n",
    "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "  // Copiamos los datos en la GPU\n",
    "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "  // Aplicamos el spencil\n",
    "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "  // Copiamos los resultados\n",
    "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "  // Verificamos que se ha hecho correctamente\n",
    "  int expected_res = 2*RADIUS+1;\n",
    "  for( i = 0; i < NUM_ELEMENTS; ++i ) {\n",
    "    if (h_out[i] != expected_res)\n",
    "    {\n",
    "      printf(\"Element h_out[%d] == %d != %d\\n\", i, h_out[i], expected_res);\n",
    "      break;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  if (i == NUM_ELEMENTS)\n",
    "    printf(\"SUCCESS!\\n\");\n",
    "\n",
    "  // Liberamos memoria\n",
    "  cudaFree(d_in);\n",
    "  cudaFree(d_out);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqC_IrbAvPU6",
    "outputId": "284e173d-d184-4840-af2c-91c7aa8b5c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==2876== NVPROF is profiling process 2876, command: ./stencil1d_v1\n",
      "SUCCESS!\n",
      "==2876== Profiling application: ./stencil1d_v1\n",
      "==2876== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   43.63%  5.6960us         1  5.6960us  5.6960us  5.6960us  [CUDA memcpy DtoH]\n",
      "                   32.84%  4.2880us         1  4.2880us  4.2880us  4.2880us  [CUDA memcpy HtoD]\n",
      "                   23.53%  3.0720us         1  3.0720us  3.0720us  3.0720us  stencil_1d(int*, int*)\n",
      "      API calls:   99.59%  187.03ms         2  93.513ms  7.0080us  187.02ms  cudaMalloc\n",
      "                    0.19%  350.98us         1  350.98us  350.98us  350.98us  cuDeviceTotalMem\n",
      "                    0.09%  163.67us        97  1.6870us     131ns  78.963us  cuDeviceGetAttribute\n",
      "                    0.06%  109.61us         2  54.804us  14.246us  95.362us  cudaFree\n",
      "                    0.04%  81.565us         2  40.782us  35.223us  46.342us  cudaMemcpy\n",
      "                    0.02%  30.194us         1  30.194us  30.194us  30.194us  cuDeviceGetName\n",
      "                    0.02%  29.932us         1  29.932us  29.932us  29.932us  cudaLaunchKernel\n",
      "                    0.00%  3.0750us         1  3.0750us  3.0750us  3.0750us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.8080us         3     602ns     148ns  1.2980us  cuDeviceGetCount\n",
      "                    0.00%  1.0740us         2     537ns     269ns     805ns  cuDeviceGet\n",
      "                    0.00%     251ns         1     251ns     251ns     251ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_v1.cu -o stencil1d_v1 -lcudadevrt\n",
    "!nvprof ./stencil1d_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yL7LaQpovPVS"
   },
   "source": [
    "Vemos que la mayoría del tiempo de GPU se dedica a la copia de elementos, pues estamos accediendo 7 veces a cada elemento del array original de entrada. En concreto, podemos ver que el 33% del tiempo se dedica a la copia de elementos del Host al Device, mientras que el cómputo propiamente dicho supone solo el 24% del tiempo de GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYHBfGFYveW6"
   },
   "source": [
    "## Versión con memoria compartida sin sincronización de threads\n",
    "\n",
    "Introducimos una modificación para hacer uso de memoria compartida a nivel de bloque (`__shared__`) y evitar el acceso repetido a las posiciones del vector. Para ello, en cada bloque cada thread copia en la memoria compartida el elemento que le corresponde, a excepción de los tres primeros, que copian dos elementos adicionales (uno de cada extremo).\n",
    "\n",
    "En este caso no utilizaremos la orden  `__syncthreads()` para sincronizar las hebras en ningún punto. Realizamos 100 ejecuciones independientes y contamos los errores que se produzcan en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgXVrCDdveW-",
    "outputId": "099a49e9-6c9f-457f-afd1-e6a95daa57f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stencil1d_v2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_v2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) \n",
    "{\n",
    "    // Reservamos la memoria compartida\n",
    "    __shared__ int temp[BLOCK_SIZE + 2*RADIUS];\n",
    " \n",
    "    // Índice central en el array global\n",
    "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    " \n",
    "    // Indice centran en el array local\n",
    "    int lindex = threadIdx.x + RADIUS;\n",
    "\n",
    "    // Cargamos los elementos a la memoria compartida\n",
    "    temp[lindex] = in[gindex];\n",
    "    if (threadIdx.x < RADIUS) \n",
    "    {\n",
    "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
    "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
    "    }\n",
    "\n",
    "    // Hacemos la operación\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
    "        result += temp[lindex + offset];\n",
    "\n",
    "    // Guardamos el resultado\n",
    "    out[gindex-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  int errors[100] = {0};\n",
    " \n",
    "  // Ejecutamos el código 100 veces independientes\n",
    "  for (int j = 0; j < 100; j++){\n",
    "      unsigned int i;\n",
    "      int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "      int *d_in, *d_out;\n",
    "\n",
    "      // Inicializamos los datos\n",
    "      for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "          h_in[i] = 1; \n",
    "\n",
    "      // Reserva memoria en la GPU\n",
    "      cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "      cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "      // Copiar los datos al dispositivo\n",
    "      cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "      stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "      cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "      int expected_res = 2*RADIUS+1;\n",
    "      for( i = 0; i < NUM_ELEMENTS; ++i ) {\n",
    "        if (h_out[i] != expected_res)\n",
    "        {\n",
    "          //printf(\"Element h_out[%d] == %d != %d\\n\", i, h_out[i], expected_res);\n",
    "         errors[j]++;\n",
    "          break;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Free out memory\n",
    "      cudaFree(d_in);\n",
    "      cudaFree(d_out);\n",
    "      cudaDeviceReset();\n",
    "  }\n",
    " \n",
    "  // Contamos los errores\n",
    "  int max_error = 0;\n",
    "  int num_error = 0;\n",
    "  for (int j = 0; j < 100; j++) {\n",
    "    num_error += errors[j];\n",
    "    if (errors[j] > max_error)\n",
    "      max_error = errors[j];\n",
    "  }\n",
    " \n",
    "  printf(\"Realizadas 100 ejecuciones independientes.\\n\");\n",
    "  printf(\"Número total de errores: %d\\n\", num_error);\n",
    "  printf(\"Máximo error en una ejecución: %d\\n\", max_error);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6RkXHZSveXO",
    "outputId": "94847002-f711-4408-8836-2009d0f31f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==2926== NVPROF is profiling process 2926, command: ./stencil1d_v2\n",
      "Realizadas 100 ejecuciones independientes.\n",
      "Número total de errores: 100\n",
      "Máximo error en una ejecución: 1\n",
      "==2926== Profiling application: ./stencil1d_v2\n",
      "==2926== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   37.69%  469.57us       100  4.6950us  4.4160us  6.2080us  [CUDA memcpy DtoH]\n",
      "                   37.18%  463.27us       100  4.6320us  4.2560us  6.0800us  [CUDA memcpy HtoD]\n",
      "                   25.13%  313.18us       100  3.1310us  3.1040us  3.2000us  stencil_1d(int*, int*)\n",
      "      API calls:   73.57%  15.3526s       200  76.763ms  6.3630us  194.64ms  cudaMalloc\n",
      "                   26.34%  5.49698s       100  54.970ms  52.567ms  59.719ms  cudaDeviceReset\n",
      "                    0.05%  9.4823ms       200  47.411us  8.7550us  137.61us  cudaFree\n",
      "                    0.03%  6.3634ms       200  31.817us  24.041us  65.748us  cudaMemcpy\n",
      "                    0.01%  2.7463ms       100  27.463us  23.181us  53.470us  cudaLaunchKernel\n",
      "                    0.00%  340.41us         1  340.41us  340.41us  340.41us  cuDeviceTotalMem\n",
      "                    0.00%  187.64us        97  1.9340us     135ns  93.019us  cuDeviceGetAttribute\n",
      "                    0.00%  26.939us         1  26.939us  26.939us  26.939us  cuDeviceGetName\n",
      "                    0.00%  13.030us         1  13.030us  13.030us  13.030us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.2350us         3     745ns     146ns  1.4940us  cuDeviceGetCount\n",
      "                    0.00%  1.4130us         2     706ns     349ns  1.0640us  cuDeviceGet\n",
      "                    0.00%     261ns         1     261ns     261ns     261ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_v2.cu -o stencil1d_v2 -lcudadevrt\n",
    "!nvprof ./stencil1d_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smvHl2xnqEks"
   },
   "source": [
    "Vemos que se reduce ligeramente el tiempo de copia de datos de CPU a GPU (unos 4.7 us), y ahora este tiempo coincide con el de la copia GPU->CPU. Sin embargo, se producen fallos semi-aleatorios en los cálculos. En concreto, en las 100 ejecuciones independientes que hemos hecho se han producido 100 fallos, uno en cada una. Esto es porque tras leer los datos no hay una barrera que sincronice todos los threads, por lo que es posible que alguno de ellos comience el cálculo del stencil antes de que estén todos los datos en memoria compartida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5GADOwRvXYX"
   },
   "source": [
    "## Versión con memoria compartida y sincronización de threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqVn3FvwvXYe",
    "outputId": "1feacf29-241b-48d5-d5fa-1d2e2625752b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stencil1d_v3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_v3.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) \n",
    "{\n",
    "    // Reservamos la memoria compartida\n",
    "    __shared__ int temp[BLOCK_SIZE + 2*RADIUS];\n",
    " \n",
    "    // Índice central en el array global\n",
    "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    " \n",
    "    // Indice centran en el array local\n",
    "    int lindex = threadIdx.x + RADIUS;\n",
    "\n",
    "    // Cargamos los elementos a la memoria compartida\n",
    "    temp[lindex] = in[gindex];\n",
    "    if (threadIdx.x < RADIUS) \n",
    "    {\n",
    "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
    "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
    "    }\n",
    " \n",
    "    __syncthreads();\n",
    "\n",
    "    // Hacemos la operación\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
    "        result += temp[lindex + offset];\n",
    "\n",
    "    // Guardamos el resultado\n",
    "    out[gindex-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  int errors[100] = {0};\n",
    " \n",
    "  // Ejecutamos el código 100 veces independientes\n",
    "  for (int j = 0; j < 100; j++){\n",
    "      unsigned int i;\n",
    "      int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "      int *d_in, *d_out;\n",
    "\n",
    "      // Inicializamos los datos\n",
    "      for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "          h_in[i] = 1; \n",
    "\n",
    "      // Reserva memoria en la GPU\n",
    "      cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "      cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "      // Copiar los datos al dispositivo\n",
    "      cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "      stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "      cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "      int expected_res = 2*RADIUS+1;\n",
    "      for( i = 0; i < NUM_ELEMENTS; ++i ) {\n",
    "        if (h_out[i] != expected_res)\n",
    "        {\n",
    "          //printf(\"Element h_out[%d] == %d != %d\\n\", i, h_out[i], expected_res);\n",
    "          errors[j]++;\n",
    "          break;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Free out memory\n",
    "      cudaFree(d_in);\n",
    "      cudaFree(d_out);\n",
    "      cudaDeviceReset();\n",
    "  }\n",
    " \n",
    "  // Contamos los errores\n",
    "  int max_error = 0;\n",
    "  int num_error = 0;\n",
    "  for (int j = 0; j < 100; j++) {\n",
    "    num_error += errors[j];\n",
    "    if (errors[j] > max_error)\n",
    "      max_error = errors[j];\n",
    "  }\n",
    " \n",
    "  printf(\"Realizadas 100 ejecuciones independientes.\\n\");\n",
    "  printf(\"Número total de errores: %d\\n\", num_error);\n",
    "  printf(\"Máximo error en una ejecución: %d\\n\", max_error);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AzCmOr9vXY1",
    "outputId": "1a038733-6952-4020-e017-a15cb49a11a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==3079== NVPROF is profiling process 3079, command: ./stencil1d_v3\n",
      "Realizadas 100 ejecuciones independientes.\n",
      "Número total de errores: 0\n",
      "Máximo error en una ejecución: 0\n",
      "==3079== Profiling application: ./stencil1d_v3\n",
      "==3079== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   37.58%  470.82us       100  4.7080us  4.4160us  6.0480us  [CUDA memcpy DtoH]\n",
      "                   36.93%  462.63us       100  4.6260us  4.2880us  6.1760us  [CUDA memcpy HtoD]\n",
      "                   25.49%  319.27us       100  3.1920us  3.1360us  3.2960us  stencil_1d(int*, int*)\n",
      "      API calls:   73.46%  15.0458s       200  75.229ms  6.2800us  187.42ms  cudaMalloc\n",
      "                   26.45%  5.41661s       100  54.166ms  52.283ms  58.709ms  cudaDeviceReset\n",
      "                    0.05%  9.5939ms       200  47.969us  8.9190us  127.93us  cudaFree\n",
      "                    0.03%  6.1591ms       200  30.795us  24.055us  52.484us  cudaMemcpy\n",
      "                    0.01%  2.8672ms       100  28.671us  24.738us  50.801us  cudaLaunchKernel\n",
      "                    0.00%  372.52us         1  372.52us  372.52us  372.52us  cuDeviceTotalMem\n",
      "                    0.00%  155.56us        97  1.6030us     135ns  65.806us  cuDeviceGetAttribute\n",
      "                    0.00%  29.607us         1  29.607us  29.607us  29.607us  cuDeviceGetName\n",
      "                    0.00%  3.7980us         1  3.7980us  3.7980us  3.7980us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.1450us         3     715ns     139ns  1.4620us  cuDeviceGetCount\n",
      "                    0.00%  1.2110us         2     605ns     259ns     952ns  cuDeviceGet\n",
      "                    0.00%     367ns         1     367ns     367ns     367ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_v3.cu -o stencil1d_v3 -lcudadevrt\n",
    "!nvprof ./stencil1d_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHZw4jc9s-LP"
   },
   "source": [
    "Vemos como esta vez no se produce ningún fallo en ninguna de las ejecuciones, gracias a la barrera `__syncthreads()` antes de comenzar los cálculos. En cuanto a la aceleración, observamos que hemos logrado reducir el tiempo de copia CPU->GPU utilizando la memoria local, que era el cuello de botella del programa. \n",
    "\n",
    "Quizás la reducción de tiempos no es muy sorprendente, pero esto puede deberse a que estamos utilizando tamaños de vector y radio relativamente pequeños. Podemos hacer una última prueba con un vector más largo y un radio de 7, para ver la aceleración obtenida frente a la versión que no usa memoria compartida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlVusvvvt8r_",
    "outputId": "94854838-601e-4078-8e3d-8e0f03dde967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==4069== NVPROF is profiling process 4069, command: ./stencil1d_v1\n",
      "SUCCESS!\n",
      "==4069== Profiling application: ./stencil1d_v1\n",
      "==4069== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   55.86%  70.625us         1  70.625us  70.625us  70.625us  [CUDA memcpy HtoD]\n",
      "                   35.66%  45.088us         1  45.088us  45.088us  45.088us  [CUDA memcpy DtoH]\n",
      "                    8.48%  10.720us         1  10.720us  10.720us  10.720us  stencil_1d(int*, int*)\n",
      "      API calls:   99.26%  177.11ms         2  88.557ms  13.125us  177.10ms  cudaMalloc\n",
      "                    0.33%  595.03us         2  297.51us  139.24us  455.78us  cudaMemcpy\n",
      "                    0.21%  378.14us         1  378.14us  378.14us  378.14us  cuDeviceTotalMem\n",
      "                    0.08%  149.84us        97  1.5440us     137ns  64.732us  cuDeviceGetAttribute\n",
      "                    0.08%  137.51us         2  68.756us  25.284us  112.23us  cudaFree\n",
      "                    0.02%  31.092us         1  31.092us  31.092us  31.092us  cudaLaunchKernel\n",
      "                    0.02%  29.732us         1  29.732us  29.732us  29.732us  cuDeviceGetName\n",
      "                    0.00%  3.7100us         1  3.7100us  3.7100us  3.7100us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.4290us         3     809ns     216ns  1.8120us  cuDeviceGetCount\n",
      "                    0.00%  1.2750us         2     637ns     265ns  1.0100us  cuDeviceGet\n",
      "                    0.00%     278ns         1     278ns     278ns     278ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define RADIUS/c\\#define RADIUS 7' stencil1d_v1.cu\n",
    "!sed -i '/#define NUM_ELEMENTS/c\\#define NUM_ELEMENTS (4096*32)' stencil1d_v1.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_v1.cu -o stencil1d_v1 -lcudadevrt\n",
    "!nvprof ./stencil1d_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNRG5rR0t9G0",
    "outputId": "e7f1b85d-97c4-40bd-9957-a055bbff25b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==4439== NVPROF is profiling process 4439, command: ./stencil1d_v3\n",
      "Realizadas 100 ejecuciones independientes.\n",
      "Número total de errores: 0\n",
      "Máximo error en una ejecución: 0\n",
      "==4439== Profiling application: ./stencil1d_v3\n",
      "==4439== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   52.47%  6.0712ms       100  60.712us  46.048us  82.847us  [CUDA memcpy HtoD]\n",
      "                   37.52%  4.3412ms       100  43.412us  41.855us  50.560us  [CUDA memcpy DtoH]\n",
      "                   10.02%  1.1594ms       100  11.593us  11.520us  11.712us  stencil_1d(int*, int*)\n",
      "      API calls:   73.35%  15.0818s       200  75.409ms  6.0240us  182.05ms  cudaMalloc\n",
      "                   26.39%  5.42669s       100  54.267ms  52.412ms  67.218ms  cudaDeviceReset\n",
      "                    0.18%  37.231ms       200  186.15us  126.52us  443.35us  cudaMemcpy\n",
      "                    0.06%  12.088ms       200  60.437us  13.037us  134.76us  cudaFree\n",
      "                    0.02%  3.1995ms       100  31.994us  27.139us  76.617us  cudaLaunchKernel\n",
      "                    0.00%  351.90us         1  351.90us  351.90us  351.90us  cuDeviceTotalMem\n",
      "                    0.00%  168.51us        97  1.7370us     132ns  81.203us  cuDeviceGetAttribute\n",
      "                    0.00%  25.385us         1  25.385us  25.385us  25.385us  cuDeviceGetName\n",
      "                    0.00%  3.1350us         1  3.1350us  3.1350us  3.1350us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.6950us         3     565ns     157ns  1.0590us  cuDeviceGetCount\n",
      "                    0.00%     944ns         2     472ns     221ns     723ns  cuDeviceGet\n",
      "                    0.00%     264ns         1     264ns     264ns     264ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!sed -i '/#define RADIUS/c\\#define RADIUS 7' stencil1d_v3.cu\n",
    "!sed -i '/#define NUM_ELEMENTS/c\\#define NUM_ELEMENTS (4096*32)' stencil1d_v3.cu\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_v3.cu -o stencil1d_v3 -lcudadevrt\n",
    "!nvprof ./stencil1d_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeQ2pndkxayD"
   },
   "source": [
    "En este caso conseguimos una aceleración del 17%, pasando de unos 70 us a unos 60 us."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "99r-TI0k_V7-",
    "6rVyeFJ1YQWw"
   ],
   "include_colab_link": true,
   "name": "Suma_y_Stencil1d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "bibliography.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
