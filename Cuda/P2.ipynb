{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO19oi1CXzIFGbGcpQk7iNy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ludvins/Practicas_PDGE/blob/master/Cuda/P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99r-TI0k_V7-"
      },
      "source": [
        "Comprobamos las características del sistema que nos ha proporcionado Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRmCimjj_eFD",
        "outputId": "4a768d00-5345-4364-b9b1-12e24beaf30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!lscpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2200.000\n",
            "BogoMIPS:            4400.00\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr4-mdOu_fo9",
        "outputId": "d14742fa-1b07-4544-ba8d-b54439f5deb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!free -h"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        538M         10G        972K        2.0G         11G\n",
            "Swap:            0B          0B          0B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF0YFAOb_hiB"
      },
      "source": [
        "Verificamos la versión de Cuda instalada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w30QGcoZ_kv1",
        "outputId": "55adfb7b-14be-45c4-e9fb-0f2a57d81d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7oDGUCF_mBK",
        "outputId": "9ae8c260-d5bd-474c-d3c8-13e11a48af5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Oct 16 15:19:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBnIRDLn_ok8"
      },
      "source": [
        "Comprobamos el directorio actual de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phb9cO6__utc",
        "outputId": "ad44ddfc-bd06-42e2-86c5-de8c27cb0020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vsdEUGy_wJO",
        "outputId": "4c76bb06-a452-4701-ccd1-64d69a4cd3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16\n",
            "drwxr-xr-x 1 root root 4096 Oct 14 16:31 .\n",
            "drwxr-xr-x 1 root root 4096 Oct 16 15:17 ..\n",
            "drwxr-xr-x 1 root root 4096 Oct 14 16:32 .config\n",
            "drwxr-xr-x 1 root root 4096 Oct 14 16:31 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiZ1LOOq_xIO",
        "outputId": "c2f95f92-ea6c-4793-cdb0-a0a7763ef8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls /"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t       tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t       tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-1.15.2  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egav_e4ULqaQ",
        "outputId": "21d048c0-870e-4da0-deb4-58b751edef50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/samples/1_Utilities/deviceQuery\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6sfqdvQLtAX",
        "outputId": "110fc05b-9dee-42fe-e395-ff1453c816ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!make"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery.o -c deviceQuery.cpp\n",
            "/usr/local/cuda-10.1/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery deviceQuery.o \n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../bin/x86_64/linux/release\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKGfxLn7Lwje",
        "outputId": "411fc2c5-5707-43de-d414-5049693515f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "!!./deviceQuery"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./deviceQuery Starting...',\n",
              " '',\n",
              " ' CUDA Device Query (Runtime API) version (CUDART static linking)',\n",
              " '',\n",
              " 'Detected 1 CUDA Capable device(s)',\n",
              " '',\n",
              " 'Device 0: \"Tesla P100-PCIE-16GB\"',\n",
              " '  CUDA Driver Version / Runtime Version          10.1 / 10.1',\n",
              " '  CUDA Capability Major/Minor version number:    6.0',\n",
              " '  Total amount of global memory:                 16281 MBytes (17071734784 bytes)',\n",
              " '  (56) Multiprocessors, ( 64) CUDA Cores/MP:     3584 CUDA Cores',\n",
              " '  GPU Max Clock rate:                            1329 MHz (1.33 GHz)',\n",
              " '  Memory Clock rate:                             715 Mhz',\n",
              " '  Memory Bus Width:                              4096-bit',\n",
              " '  L2 Cache Size:                                 4194304 bytes',\n",
              " '  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)',\n",
              " '  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers',\n",
              " '  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers',\n",
              " '  Total amount of constant memory:               65536 bytes',\n",
              " '  Total amount of shared memory per block:       49152 bytes',\n",
              " '  Total number of registers available per block: 65536',\n",
              " '  Warp size:                                     32',\n",
              " '  Maximum number of threads per multiprocessor:  2048',\n",
              " '  Maximum number of threads per block:           1024',\n",
              " '  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)',\n",
              " '  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)',\n",
              " '  Maximum memory pitch:                          2147483647 bytes',\n",
              " '  Texture alignment:                             512 bytes',\n",
              " '  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)',\n",
              " '  Run time limit on kernels:                     No',\n",
              " '  Integrated GPU sharing Host Memory:            No',\n",
              " '  Support host page-locked memory mapping:       Yes',\n",
              " '  Alignment requirement for Surfaces:            Yes',\n",
              " '  Device has ECC support:                        Enabled',\n",
              " '  Device supports Unified Addressing (UVA):      Yes',\n",
              " '  Device supports Compute Preemption:            Yes',\n",
              " '  Supports Cooperative Kernel Launch:            Yes',\n",
              " '  Supports MultiDevice Co-op Kernel Launch:      Yes',\n",
              " '  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4',\n",
              " '  Compute Mode:',\n",
              " '     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >',\n",
              " '',\n",
              " 'deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 1',\n",
              " 'Result = PASS']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2CtfWTcAASW"
      },
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "El código de ejemplo en suma de los elementos de un vector realiza la\n",
        "suma de dos vectores en la GPU.\n",
        "1. Comente losdiferentes casos propuestos en el ejemplo y\n",
        "conteste a las preguntas.\n",
        "2. Se propone extender el código de este ejemplo para que realice\n",
        "la resta (o suma) de matrices cuadradas de dimensión N. \n",
        "  - Configure adecuadamente el Grid de threads para aceptar\n",
        "matrices de cualquier tamaño.\n",
        "  - En el kernel, utilice las variables blockIdx y threadIdx\n",
        "adecuadamente para acceder a una estructura bidimensional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmyV4CtLGm1v"
      },
      "source": [
        "### Suma de Vectores completa\n",
        "\n",
        "Vemos a continuación el código concreto que permite sumar dos vectores guardando el resultado en el segundo de estos.\n",
        "\n",
        "En él, utilizamos un total de 512 threads por bloque."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m90eOq9eAaDM",
        "outputId": "5e7e0e69-e493-4719-b6f2-1b6a4aef39b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile suma_vec.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// __global__ indica que se ejecuta en el dispositivo, por lo tanto\n",
        "// x, y,deben apuntar a memoria en el dispositivo.\n",
        "__global__ void add(float *x, float *y, int size) {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (i < size )\n",
        "        y[i]=x[i]+y[i];\n",
        "}\n",
        "\n",
        "// Define array size\n",
        "#define N (1024*1024)\n",
        "// Define number of threads per block\n",
        "#define THREADS_PER_BLOCK 512\n",
        "\n",
        "int main(void) {\n",
        "    // Numero de datos\n",
        "    float *x, *y;                 // = new float[N];\n",
        "    float *d_x, *d_y;             // = new float[N]; \n",
        "    int size = N*sizeof(float);\n",
        "\n",
        "    // Reservamos memoria en el dispositivo.\n",
        "    cudaMalloc((void **)&d_x, size);\n",
        "    cudaMalloc((void **)&d_y, size);\n",
        "\n",
        "    //Reservamos moemoria en el host\n",
        "    x = (float *)malloc(size);\n",
        "    y = (float *)malloc(size);\n",
        "    for (int i =0; i < N; i++ ){\n",
        "        x[i]= 1.0f;\n",
        "        y[i]= 2.0f;\n",
        "    }\n",
        "\n",
        "    // Copiamos los valores al dispositivo\n",
        "    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lanzamos add\n",
        "    add<<<N/THREADS_PER_BLOCK, THREADS_PER_BLOCK>>>(d_x, d_y, N);\n",
        "\n",
        "    // Esperamos que se realicen todas las iteraciones.\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copiamos el resultado al host\n",
        "    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    // Comprobamos los resultados\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "   \n",
        "    for (int i=0; i <N; i++){\n",
        "        maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
        "        if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
        "    std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "    free(x); free(y);\n",
        "    cudaFree(d_x); cudaFree(d_y);\n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma_vec.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siRfJpVzA1U0"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma_vec.cu -o suma_vec -lcudadevrt"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRAyRqQ7A1qi",
        "outputId": "7c50321a-86f1-42a6-956d-c2fe960f0c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!./suma_vec"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "suma de 1048576 Elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CrNSHn7A6uU",
        "outputId": "850d024c-6228-45ca-dc1c-f2426c075cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!nvprof ./suma_vec"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1124== NVPROF is profiling process 1124, command: ./suma_vec\n",
            "suma de 4194304 Elementos\n",
            "Número de Errores: 0\n",
            "Max error: 0\n",
            "==1124== Profiling application: ./suma_vec\n",
            "==1124== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   58.64%  9.3680ms         1  9.3680ms  9.3680ms  9.3680ms  [CUDA memcpy DtoH]\n",
            "                   40.77%  6.5130ms         2  3.2565ms  3.2527ms  3.2603ms  [CUDA memcpy HtoD]\n",
            "                    0.59%  94.558us         1  94.558us  94.558us  94.558us  add(float*, float*, float*)\n",
            "      API calls:   88.40%  154.30ms         3  51.433ms  88.906us  154.11ms  cudaMalloc\n",
            "                   10.01%  17.474ms         3  5.8247ms  3.4203ms  10.582ms  cudaMemcpy\n",
            "                    1.16%  2.0296ms         3  676.54us  167.66us  1.1382ms  cudaFree\n",
            "                    0.21%  362.95us         1  362.95us  362.95us  362.95us  cuDeviceTotalMem\n",
            "                    0.09%  165.22us        97  1.7030us     133ns  54.388us  cuDeviceGetAttribute\n",
            "                    0.09%  153.80us         1  153.80us  153.80us  153.80us  cudaDeviceSynchronize\n",
            "                    0.02%  32.859us         1  32.859us  32.859us  32.859us  cudaLaunchKernel\n",
            "                    0.01%  16.210us         1  16.210us  16.210us  16.210us  cuDeviceGetName\n",
            "                    0.00%  2.9630us         1  2.9630us  2.9630us  2.9630us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1790us         3     726ns     201ns  1.4800us  cuDeviceGetCount\n",
            "                    0.00%  1.4460us         2     723ns     316ns  1.1300us  cuDeviceGet\n",
            "                    0.00%     267ns         1     267ns     267ns     267ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWb6N439J73j"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8w-6yuRKok2"
      },
      "source": [
        "Si ejecutamos el programa utilizando un total de 256 threads por bloque y un solo bloque, es decir:\n",
        "```\n",
        "add<<<1, 256>>>(d_x, d_y, N);\n",
        "```\n",
        "Obtendríamos que solo se ha realizado la operación sobre 256 valores de los N posibles, esto mismo pasa utilizando 256 bloques y un thread en cada uno. \n",
        "\n",
        "Por otro lado, si ejecutamos dicha función sin quitar el bucle for que teníamos inicialmente en la función add:\n",
        "\n",
        "```\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "    for (int i =0; i < n; i++ ){\n",
        "        y[i]=x[i]+y[i];\n",
        "    }\n",
        "}\n",
        "```\n",
        "obtendríamos que cada thread lanzado realizaría todas las sumas, pudiendo ocurrir que se pisaran unas a otras\n",
        "\n",
        "```\n",
        "Suma de 1048576 elementos\n",
        "Número de errores: 3473\n",
        "Max error: 2\n",
        "```\n",
        "\n",
        "**Pendiente: Comentar <1,256> sin datarace y suma en la GPU con paralelismo de bloques.Prueba con mas Thread por bloque. Pruebas variando N y la complejidad de la\n",
        "operación matemática.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKdkqK87NQDw"
      },
      "source": [
        "## Suma o resta de matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etw0Z2fcGlaD",
        "outputId": "466de9bc-bd1f-4694-8745-2093e488abb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile suma_mat.cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// __global__ indica que se ejecuta en el dispositivo, por lo tanto\n",
        "// x, y,deben apuntar a memoria en el dispositivo.\n",
        "\n",
        "__global__ void add(float **x, float **y, int row, int col) {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int j = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "\n",
        "    y[i][j] = x[i][j] + y[i][j];\n",
        "}\n",
        "\n",
        "// Define matriz size\n",
        "#define R 512\n",
        "#define C 512\n",
        "// Define number of threads per block\n",
        "#define THREADS_PER_BLOCK 512\n",
        "\n",
        "int main(void) {\n",
        "    // Numero de datos\n",
        "    float **x, **y;                 // = new float[N];\n",
        "    float **d_x, **d_y;             // = new float[N]; \n",
        "    int size = C*R*sizeof(float);\n",
        "\n",
        "    // Reservamos memoria en el dispositivo.\n",
        "    cudaMalloc((void **)&d_x, size);\n",
        "    cudaMalloc((void **)&d_y, size);\n",
        "\n",
        "    //Reservamos moemoria en el host\n",
        "    x = (float **)malloc(R*sizeof(float*));\n",
        "    y = (float **)malloc(R*sizeof(float*));\n",
        "\n",
        "    for (int i =0; i < R; i++ ){\n",
        "        x[i] = (float *)malloc(C * sizeof(float));\n",
        "        y[i] = (float *)malloc(C * sizeof(float));\n",
        "\n",
        "        for (int j = 0; j < C; j++){\n",
        "            x[i][j] = 1.0f;\n",
        "            y[i][j] = 2.0f;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copiamos los valores al dispositivo\n",
        "    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lanzamos add\n",
        "    dim3 threadsPerBlock(512, 512);\n",
        "    dim3 numBlocks(R/threadsPerBlock.x, C/threadsPerBlock.y);\n",
        "    add<<<numBlocks, threadsPerBlock>>>(d_x, d_y, R, C);\n",
        "\n",
        "    // Esperamos que se realicen todas las iteraciones.\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copiamos el resultado al host\n",
        "    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    // Comprobamos los resultados\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "   \n",
        "    for (int i=0; i <R; i++){\n",
        "        for (int j = 0; j < C; j++){\n",
        "          maxError=fmax(maxError,fabs(y[i][j]-3.0f));\n",
        "          if (y[i][j] != 3.0) contError++; \n",
        "        }\n",
        "    }\n",
        "    std::cout << \"suma de \" << R*C << \" Elementos\" << std::endl;\n",
        "    std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "    free(x); free(y);\n",
        "    cudaFree(d_x); cudaFree(d_y);\n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma_mat.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvCVjyGaI4MU"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true suma_mat.cu -o suma_mat -lcudadevrt"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrxmZhL2L97F",
        "outputId": "84ed3d0c-9d0f-4578-c710-20c85a4f9000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!./suma_mat"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "suma de 262144 Elementos\n",
            "Número de Errores: 262144\n",
            "Max error: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV_FLBxDRxaN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}